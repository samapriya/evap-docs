{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Reservoir Evaporation API Documentation","text":""},{"location":"#overview","title":"Overview","text":"<p>The Reservoir Evaporation API provides public access to historical and near-real-time daily evaporation estimates from Bureau of Reclamation reservoirs located across 17 western states.</p> <p>This API delivers high-quality data records of evaporation rates and volumes for major reservoirs. The evaporation estimates incorporate meteorological forcing data and reservoir storage information to provide the best available estimates of reservoir evaporation.</p>"},{"location":"#about-this-project","title":"About This Project","text":"<p>Open-water evaporation represents a complex physical process that influences both the water and energy budgets of a lake or reservoir. Though open-water evaporation is critical for water quality, water distribution, and legal accounting, developing reliable estimates is challenging.</p> <p>Historically, water management agencies such as the Bureau of Reclamation (Reclamation) have relied on evaporation estimates from Class A pans for water budget and accounting purposes. While simple and relatively inexpensive to maintain, Class A pans and the associated evaporation estimates have known biases relative to more advanced estimation techniques. This bias, which can depend on water body characteristics like depth and volume, is often attributed to a lack of heat storage in Class A pans relative to real water bodies.</p> <p>This project developed a daily reservoir evaporation database which can be freely accessed and visualized by water managers and stakeholders. This database contains historical and near real-time, high quality data records of evaporation rates and volumes for major reservoirs.</p>"},{"location":"#collaborative-development","title":"Collaborative Development","text":"<p>This API was collaboratively developed by the Bureau of Reclamation (BOR) and Desert Research Institute.</p> <p> <p></p> <p></p>"},{"location":"#disclaimer","title":"Disclaimer","text":"<p>Data and information provided through this application are part of an active research project and should be considered provisional and subject to change. Users should perform thorough review prior to operational application and decision making.</p>"},{"location":"#additional-resources","title":"Additional Resources","text":"<ul> <li>Abatzoglou, J. T. (2013), Development of gridded surface meteorological data for ecological applications and modelling. Int. J. Climatol., 33: 121\u2013131.</li> <li>De Pondeca, M. S. F. V., and Coauthors, 2011: The Real-Time Mesoscale Analysis at NOAA's National Centers for Environmental Prediction: Current status and development. Wea. Forecasting, 26, 593\u2013612, https://doi.org/10.1175/WAF-D-10-05037.1.</li> <li>Tanny, J., and Coauthors, 2008: Evaporation from a small water reservoir: Direct measurements and estimates. J. Hydrology, 351, 218-229.</li> <li>Zhao, G., and H. Gao, 2019: Estimating reservoir evaporation losses for the united states: Fusing remote sensing and modeling approaches. Remote Sensing of Environment, 226, 109\u2013124.</li> <li>Zhao, B., and Coauthors, 2023: Developing a Daily Lake Evaporation Model and Generating a Long-term Daily Reservoir Evaporation Dataset in Texas. Submitted to Water Resources Research.</li> </ul>"},{"location":"appendix/","title":"Appendix","text":""},{"location":"appendix/#available-variables","title":"Available Variables","text":""},{"location":"appendix/#reservoir-variables","title":"Reservoir Variables","text":"<p>The following variables are available for reservoirs across different datasets:</p>"},{"location":"appendix/#rtma-dataset-weather-variables","title":"RTMA Dataset (Weather Variables)","text":"Variable Description Units (Metric) Units (English) pr Precipitation mm in tmmx_c Maximum temperature \u00b0C \u00b0F tmmn_c Minimum temperature \u00b0C \u00b0F vpd_kpa Vapor pressure deficit kPa kPa vs2m Wind speed at 2 meters m/s mph srad Solar radiation W/m\u00b2 W/m\u00b2 th Specific humidity kg/kg kg/kg sph_kgkg Specific humidity kg/kg kg/kg pres_pa Air pressure Pa Pa"},{"location":"appendix/#res-dataset-reservoir-physical-variables","title":"RES Dataset (Reservoir Physical Variables)","text":"Variable Description Units (Metric) Units (English) stage_m Water surface elevation m ft area_m2 Surface area m\u00b2 acre depth_m Average depth m ft"},{"location":"appendix/#lem-dataset-energy-balance-variables","title":"LEM Dataset (Energy Balance Variables)","text":"Variable Description Units (Metric) Units (English) E_hs Heat storage evaporation mm/day in/day E_nhs No heat storage evaporation mm/day in/day Rn Net radiation W/m\u00b2 W/m\u00b2 Tw Water temperature \u00b0C \u00b0F Tw0 Surface water temperature \u00b0C \u00b0F Fetch Fetch m ft Lerr Latent heat of evaporation W/m\u00b2 W/m\u00b2"},{"location":"appendix/#nete-volume-calcs-dataset-evaporation-variables","title":"NETE-VOLUME-CALCS Dataset (Evaporation Variables)","text":"Variable Description Units (Metric) Units (English) NetE Net evaporation mm/day in/day E_volume Evaporation volume m\u00b3 acre-ft NetE_volume Net evaporation volume m\u00b3 acre-ft"},{"location":"appendix/#station-variables","title":"Station Variables","text":"<p>The following variables are available for stations:</p> Variable Description Units (Metric) Units (English) ATemp Air temperature \u00b0C \u00b0F ATemp_Min Minimum air temperature \u00b0C \u00b0F ATemp_Max Maximum air temperature \u00b0C \u00b0F BP Barometric pressure hPa inHg BR Bowen ratio unitless unitless Ce Bulk transfer coefficient unitless unitless DO Dissolved oxygen mg/L mg/L DO_percent Dissolved oxygen percentage % % EnergyT Energy balance term W/m\u00b2 W/m\u00b2 ETo Reference evapotranspiration (grass) mm/day in/day ETr Reference evapotranspiration (alfalfa) mm/day in/day evap_1 Evaporation method 1 mm/day in/day evap_2 Evaporation method 2 mm/day in/day evap_3 Evaporation method 3 mm/day in/day evap_4 Evaporation method 4 mm/day in/day evap_5 Evaporation method 5 mm/day in/day HSEnergyFlux Heat storage energy flux W/m\u00b2 W/m\u00b2 IncomingSR Incoming solar radiation W/m\u00b2 W/m\u00b2 inflow Inflow m\u00b3/s cfs SurfaceT Surface temperature \u00b0C \u00b0F MO_StabilityL Monin-Obukhov stability length m ft NC_EnergyStored Net change in energy stored W/m\u00b2 W/m\u00b2 NR Net radiation W/m\u00b2 W/m\u00b2 NW_AdvectedE Net advected energy W/m\u00b2 W/m\u00b2 outflow Outflow m\u00b3/s cfs PH pH unitless unitless RH Relative humidity % % SamplingD Sampling depth m ft SkinTemp Skin temperature \u00b0C \u00b0F SpecConduct Specific conductance \u03bcS/cm \u03bcS/cm SWin Incoming shortwave radiation W/m\u00b2 W/m\u00b2 VP Vapor pressure kPa kPa VPD Vapor pressure deficit kPa kPa WTemp Water temperature \u00b0C \u00b0F WVD Wind vector direction degrees degrees WD Wind direction degrees degrees WS Wind speed m/s mph PofDays Percentage of days with data % %"},{"location":"appendix/#http-status-codes","title":"HTTP Status Codes","text":"<p>The API may return the following HTTP status codes:</p> Status Code Description 200 Successful response 401 Unauthorized (invalid or missing API key) 404 Not found (resource not found) 422 Validation error (invalid parameters) 500 Server error"},{"location":"appendix/#data-quality-flags","title":"Data Quality Flags","text":"<p>The API may include quality flags in the response data. These flags indicate the quality or reliability of the data:</p> Flag Description 0 Good data 1 Suspect data (automatically flagged) 2 Suspect data (manually flagged) 3 Missing data (gap filled) 9 Missing data (not filled)"},{"location":"appendix/#file-formats","title":"File Formats","text":""},{"location":"appendix/#shapefile-components","title":"Shapefile Components","text":"<p>When uploading shapefiles to filter reservoirs or stations by location, the following files are required:</p> File Extension Description .shp The main file that stores the geometry .dbf The database file that stores the attributes .prj The projection file that stores the coordinate system .shx The index file that stores the index of the geometry"},{"location":"appendix/#glossary","title":"Glossary","text":"Term Definition Evaporation The process by which water changes from a liquid to a gas or vapor Net Evaporation The difference between evaporation and precipitation (evaporation minus precipitation) Reservoir A large natural or artificial lake used as a source of water supply Timeseries A series of data points indexed in time order Metadata Data that provides information about other data API Application Programming Interface REST Representational State Transfer, an architectural style for APIs JSON JavaScript Object Notation, a lightweight data-interchange format CSV Comma-Separated Values, a text file format that uses commas to separate values Dataset A collection of data Variable A measurable property Units The standard of measurement Metric The International System of Units (SI) English The US Customary Units Quality Flag An indicator of the quality or reliability of the data Shapefile A geospatial vector data format for geographic information system software"},{"location":"changelog/","title":"Changelog","text":""},{"location":"examples/","title":"Examples","text":"<p>This section provides example code snippets for common tasks using the Reservoir Evaporation API.</p>"},{"location":"examples/#setup","title":"Setup","text":"PythoncURL <pre><code>import requests\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport json\n\n# API configuration\nAPI_KEY = \"your_api_key_here\"\nBASE_URL = \"https://api-url.example\"  # Replace with the actual API base URL\nHEADERS = {\n    \"api-key\": API_KEY\n}\n</code></pre> <pre><code># Store your API key and base URL for reuse\nAPI_KEY=\"your_api_key_here\"\nBASE_URL=\"https://api-url.example\"  # Replace with the actual API base URL\n</code></pre>"},{"location":"examples/#get-available-reservoirs","title":"Get Available Reservoirs","text":"PythoncURL <pre><code>def get_reservoirs():\n    \"\"\"Get a list of available reservoirs.\"\"\"\n    url = f\"{BASE_URL}/info/list_RES_NAMES\"\n    response = requests.get(url, headers=HEADERS)\n\n    if response.status_code == 200:\n        return response.json()\n    else:\n        print(f\"Error: {response.status_code}\")\n        return None\n\n# Example usage\nreservoirs = get_reservoirs()\nprint(f\"Number of reservoirs: {len(reservoirs)}\")\nprint(\"First 5 reservoirs:\")\nfor res in reservoirs[:5]:\n    print(f\"- {res}\")\n</code></pre> <pre><code># Get a list of available reservoirs\ncurl -X GET \"${BASE_URL}/info/list_RES_NAMES\" \\\n     -H \"api-key: ${API_KEY}\" \\\n     -H \"Content-Type: application/json\"\n</code></pre>"},{"location":"examples/#get-reservoir-metadata","title":"Get Reservoir Metadata","text":"PythoncURL <pre><code>def get_reservoir_metadata(reservoir_names):\n    \"\"\"Get metadata for specified reservoirs.\"\"\"\n    url = f\"{BASE_URL}/metadata/reservoirs\"\n    params = {\n        \"RES_NAMES\": \",\".join(reservoir_names),\n        \"output_format\": \"json\"\n    }\n\n    response = requests.get(url, headers=HEADERS, params=params)\n\n    if response.status_code == 200:\n        return response.json()\n    else:\n        print(f\"Error: {response.status_code}\")\n        return None\n\n# Example usage\nreservoir_metadata = get_reservoir_metadata([\"LAKE ALICE\", \"LAKE ESTES\"])\nfor res in reservoir_metadata:\n    print(f\"Reservoir: {res['res_name']}\")\n    print(f\"  Latitude: {res['latitude']}\")\n    print(f\"  Longitude: {res['longitude']}\")\n    print(f\"  State: {res['state']}\")\n</code></pre> <pre><code># Get metadata for specified reservoirs\ncurl -X GET \"${BASE_URL}/metadata/reservoirs?RES_NAMES=LAKE%20ALICE,LAKE%20ESTES&amp;output_format=json\" \\\n     -H \"api-key: ${API_KEY}\"\n</code></pre>"},{"location":"examples/#get-timeseries-data-for-a-reservoir","title":"Get Timeseries Data for a Reservoir","text":"PythoncURL <pre><code>def get_reservoir_timeseries(reservoir_name, start_date, end_date):\n    \"\"\"Get timeseries data for a reservoir.\"\"\"\n    url = f\"{BASE_URL}/timeseries/daily/reservoirs/daterange\"\n    params = {\n        \"RES_NAMES\": reservoir_name,\n        \"datasets\": \"nete-volume-calcs\",\n        \"variables\": \"NetE,E_volume\",\n        \"start_date\": start_date,\n        \"end_date\": end_date,\n        \"units\": \"metric\",\n        \"output_format\": \"json\"\n    }\n\n    response = requests.get(url, headers=HEADERS, params=params)\n\n    if response.status_code == 200:\n        return response.json()\n    else:\n        print(f\"Error: {response.status_code}\")\n        return None\n\n# Example usage\ndata = get_reservoir_timeseries(\"LAKE ALICE\", \"2020-01-01\", \"2020-12-31\")\n\n# Convert to pandas DataFrame for analysis\ndf = pd.DataFrame(data)\ndf['date'] = pd.to_datetime(df['date'])\ndf.set_index('date', inplace=True)\n\n# Plot the data\nplt.figure(figsize=(12, 6))\nplt.plot(df.index, df['NetE'], label='Net Evaporation')\nplt.title('Net Evaporation for LAKE ALICE (2020)')\nplt.xlabel('Date')\nplt.ylabel('Net Evaporation (mm/day)')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n</code></pre> <pre><code># Get timeseries data for a reservoir\ncurl -X GET \"${BASE_URL}/timeseries/daily/reservoirs/daterange?RES_NAMES=LAKE%20ALICE&amp;datasets=nete-volume-calcs&amp;variables=NetE,E_volume&amp;start_date=2020-01-01&amp;end_date=2020-12-31&amp;units=metric&amp;output_format=json\" \\\n     -H \"api-key: ${API_KEY}\"\n</code></pre>"},{"location":"examples/#compare-evaporation-between-multiple-reservoirs","title":"Compare Evaporation Between Multiple Reservoirs","text":"PythoncURL <pre><code>def compare_reservoirs(reservoir_names, start_date, end_date, variable=\"NetE\"):\n    \"\"\"Compare a variable between multiple reservoirs.\"\"\"\n    url = f\"{BASE_URL}/timeseries/daily/reservoirs/daterange\"\n    params = {\n        \"RES_NAMES\": \",\".join(reservoir_names),\n        \"datasets\": \"nete-volume-calcs\",\n        \"variables\": variable,\n        \"start_date\": start_date,\n        \"end_date\": end_date,\n        \"units\": \"metric\",\n        \"output_format\": \"json\"\n    }\n\n    response = requests.get(url, headers=HEADERS, params=params)\n\n    if response.status_code == 200:\n        return response.json()\n    else:\n        print(f\"Error: {response.status_code}\")\n        return None\n\n# Example usage\nreservoirs_to_compare = [\"LAKE ALICE\", \"LAKE ESTES\", \"RUEDI RESERVOIR\"]\ncomparison_data = compare_reservoirs(reservoirs_to_compare, \"2020-06-01\", \"2020-08-31\")\n\n# Process and visualize data\ndf = pd.DataFrame(comparison_data)\ndf['date'] = pd.to_datetime(df['date'])\n\n# Pivot the data to have one column per reservoir\npivot_df = df.pivot_table(index='date', columns='res_name', values='NetE')\n\n# Plot the data\nplt.figure(figsize=(12, 6))\nfor reservoir in reservoirs_to_compare:\n    plt.plot(pivot_df.index, pivot_df[reservoir], label=reservoir)\n\nplt.title('Net Evaporation Comparison (Summer 2020)')\nplt.xlabel('Date')\nplt.ylabel('Net Evaporation (mm/day)')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n</code></pre> <pre><code># Compare evaporation between multiple reservoirs\ncurl -X GET \"${BASE_URL}/timeseries/daily/reservoirs/daterange?RES_NAMES=LAKE%20ALICE,LAKE%20ESTES,RUEDI%20RESERVOIR&amp;datasets=nete-volume-calcs&amp;variables=NetE&amp;start_date=2020-06-01&amp;end_date=2020-08-31&amp;units=metric&amp;output_format=json\" \\\n     -H \"api-key: ${API_KEY}\"\n</code></pre>"},{"location":"examples/#calculate-monthly-evaporation-volumes","title":"Calculate Monthly Evaporation Volumes","text":"PythoncURL <pre><code>def get_monthly_evaporation_volumes(reservoir_name, year):\n    \"\"\"Calculate monthly evaporation volumes for a reservoir.\"\"\"\n    start_date = f\"{year}-01-01\"\n    end_date = f\"{year}-12-31\"\n\n    url = f\"{BASE_URL}/timeseries/daily/reservoirs/daterange\"\n    params = {\n        \"RES_NAMES\": reservoir_name,\n        \"datasets\": \"nete-volume-calcs\",\n        \"variables\": \"E_volume\",\n        \"start_date\": start_date,\n        \"end_date\": end_date,\n        \"units\": \"metric\",\n        \"output_format\": \"json\"\n    }\n\n    response = requests.get(url, headers=HEADERS, params=params)\n\n    if response.status_code == 200:\n        data = response.json()\n        df = pd.DataFrame(data)\n        df['date'] = pd.to_datetime(df['date'])\n        df.set_index('date', inplace=True)\n\n        # Calculate monthly totals\n        monthly_data = df.resample('M').sum()\n        monthly_data.index = monthly_data.index.strftime('%b')\n\n        return monthly_data\n    else:\n        print(f\"Error: {response.status_code}\")\n        return None\n\n# Example usage\nmonthly_volumes = get_monthly_evaporation_volumes(\"LAKE MEAD\", 2020)\n\n# Plot monthly volumes\nplt.figure(figsize=(12, 6))\nplt.bar(monthly_volumes.index, monthly_volumes['E_volume'])\nplt.title('Monthly Evaporation Volumes for LAKE MEAD (2020)')\nplt.xlabel('Month')\nplt.ylabel('Evaporation Volume (cubic meters)')\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n</code></pre> <pre><code># Get monthly evaporation volumes data\ncurl -X GET \"${BASE_URL}/timeseries/daily/reservoirs/daterange?RES_NAMES=LAKE%20MEAD&amp;datasets=nete-volume-calcs&amp;variables=E_volume&amp;start_date=2020-01-01&amp;end_date=2020-12-31&amp;units=metric&amp;output_format=json\" \\\n     -H \"api-key: ${API_KEY}\"\n</code></pre>"},{"location":"examples/#retrieve-and-analyze-weather-data-for-a-reservoir","title":"Retrieve and Analyze Weather Data for a Reservoir","text":"PythoncURL <pre><code>def get_weather_data(reservoir_name, start_date, end_date):\n    \"\"\"Get weather data for a reservoir.\"\"\"\n    url = f\"{BASE_URL}/timeseries/daily/reservoirs/daterange\"\n    params = {\n        \"RES_NAMES\": reservoir_name,\n        \"datasets\": \"rtma\",\n        \"variables\": \"pr,tmmx_c,tmmn_c,vpd_kpa,srad\",\n        \"start_date\": start_date,\n        \"end_date\": end_date,\n        \"units\": \"metric\",\n        \"output_format\": \"json\"\n    }\n\n    response = requests.get(url, headers=HEADERS, params=params)\n\n    if response.status_code == 200:\n        return response.json()\n    else:\n        print(f\"Error: {response.status_code}\")\n        return None\n\n# Example usage\nweather_data = get_weather_data(\"LAKE POWELL\", \"2020-06-01\", \"2020-08-31\")\ndf = pd.DataFrame(weather_data)\ndf['date'] = pd.to_datetime(df['date'])\ndf.set_index('date', inplace=True)\n\n# Calculate monthly averages\nmonthly_weather = df.resample('M').agg({\n    'pr': 'sum',\n    'tmmx_c': 'mean',\n    'tmmn_c': 'mean',\n    'vpd_kpa': 'mean',\n    'srad': 'mean'\n})\n\nprint(\"Monthly Weather Summary for LAKE POWELL (Summer 2020):\")\nprint(f\"Month | Total Precip (mm) | Avg Max Temp (\u00b0C) | Avg Min Temp (\u00b0C)\")\nfor idx, row in monthly_weather.iterrows():\n    month = idx.strftime('%b %Y')\n    print(f\"{month} | {row['pr']:.1f} | {row['tmmx_c']:.1f} | {row['tmmn_c']:.1f}\")\n</code></pre> <pre><code># Get weather data for a reservoir\ncurl -X GET \"${BASE_URL}/timeseries/daily/reservoirs/daterange?RES_NAMES=LAKE%20POWELL&amp;datasets=rtma&amp;variables=pr,tmmx_c,tmmn_c,vpd_kpa,srad&amp;start_date=2020-06-01&amp;end_date=2020-08-31&amp;units=metric&amp;output_format=json\" \\\n     -H \"api-key: ${API_KEY}\"\n</code></pre>"},{"location":"examples/#working-with-multiple-datasets","title":"Working with Multiple Datasets","text":""},{"location":"examples/#combine-evaporation-and-weather-data","title":"Combine Evaporation and Weather Data","text":"PythoncURL <pre><code>def combine_datasets(reservoir_name, start_date, end_date):\n    \"\"\"Combine evaporation and weather data for analysis.\"\"\"\n    # Get evaporation data\n    evap_url = f\"{BASE_URL}/timeseries/daily/reservoirs/daterange\"\n    evap_params = {\n        \"RES_NAMES\": reservoir_name,\n        \"datasets\": \"nete-volume-calcs\",\n        \"variables\": \"NetE,E_volume\",\n        \"start_date\": start_date,\n        \"end_date\": end_date,\n        \"units\": \"metric\",\n        \"output_format\": \"json\"\n    }\n\n    evap_response = requests.get(evap_url, headers=HEADERS, params=evap_params)\n\n    # Get weather data\n    weather_url = f\"{BASE_URL}/timeseries/daily/reservoirs/daterange\"\n    weather_params = {\n        \"RES_NAMES\": reservoir_name,\n        \"datasets\": \"rtma\",\n        \"variables\": \"pr,tmmx_c,tmmn_c,vpd_kpa,srad\",\n        \"start_date\": start_date,\n        \"end_date\": end_date,\n        \"units\": \"metric\",\n        \"output_format\": \"json\"\n    }\n\n    weather_response = requests.get(weather_url, headers=HEADERS, params=weather_params)\n\n    if evap_response.status_code == 200 and weather_response.status_code == 200:\n        evap_data = pd.DataFrame(evap_response.json())\n        weather_data = pd.DataFrame(weather_response.json())\n\n        # Prepare data\n        evap_data['date'] = pd.to_datetime(evap_data['date'])\n        evap_data.set_index(['date', 'res_name'], inplace=True)\n\n        weather_data['date'] = pd.to_datetime(weather_data['date'])\n        weather_data.set_index(['date', 'res_name'], inplace=True)\n\n        # Merge datasets\n        combined_data = pd.merge(evap_data, weather_data, left_index=True, right_index=True)\n\n        return combined_data\n    else:\n        print(f\"Error: {evap_response.status_code} or {weather_response.status_code}\")\n        return None\n\n# Example usage\ncombined_data = combine_datasets(\"LAKE MEAD\", \"2020-06-01\", \"2020-08-31\")\ncombined_data.reset_index(inplace=True)\n\n# Calculate correlation between variables\ncorrelation = combined_data[['NetE', 'tmmx_c', 'vpd_kpa', 'srad']].corr()\nprint(\"Correlation Matrix:\")\nprint(correlation)\n\n# Plot relationship between temperature and evaporation\nplt.figure(figsize=(10, 6))\nplt.scatter(combined_data['tmmx_c'], combined_data['NetE'])\nplt.title('Relationship Between Maximum Temperature and Net Evaporation')\nplt.xlabel('Maximum Temperature (\u00b0C)')\nplt.ylabel('Net Evaporation (mm/day)')\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n</code></pre> <pre><code># Get evaporation data\ncurl -X GET \"${BASE_URL}/timeseries/daily/reservoirs/daterange?RES_NAMES=LAKE%20MEAD&amp;datasets=nete-volume-calcs&amp;variables=NetE,E_volume&amp;start_date=2020-06-01&amp;end_date=2020-08-31&amp;units=metric&amp;output_format=json\" \\\n     -H \"api-key: ${API_KEY}\" &gt; evap_data.json\n\n# Get weather data\ncurl -X GET \"${BASE_URL}/timeseries/daily/reservoirs/daterange?RES_NAMES=LAKE%20MEAD&amp;datasets=rtma&amp;variables=pr,tmmx_c,tmmn_c,vpd_kpa,srad&amp;start_date=2020-06-01&amp;end_date=2020-08-31&amp;units=metric&amp;output_format=json\" \\\n     -H \"api-key: ${API_KEY}\" &gt; weather_data.json\n\n# Note: Further processing would need to be done with tools like jq or imported into another tool\n</code></pre>"},{"location":"examples/#exporting-data-to-csv","title":"Exporting Data to CSV","text":"PythoncURL <pre><code>def export_data_to_csv(reservoir_names, start_date, end_date, output_file):\n    \"\"\"Export data for multiple reservoirs to CSV.\"\"\"\n    url = f\"{BASE_URL}/timeseries/daily/reservoirs/daterange\"\n    params = {\n        \"RES_NAMES\": \",\".join(reservoir_names),\n        \"datasets\": \"nete-volume-calcs\",\n        \"variables\": \"NetE,E_volume\",\n        \"start_date\": start_date,\n        \"end_date\": end_date,\n        \"units\": \"metric\",\n        \"output_format\": \"json\"\n    }\n\n    response = requests.get(url, headers=HEADERS, params=params)\n\n    if response.status_code == 200:\n        data = response.json()\n        df = pd.DataFrame(data)\n        df.to_csv(output_file, index=False)\n        print(f\"Data exported to {output_file}\")\n        return True\n    else:\n        print(f\"Error: {response.status_code}\")\n        return False\n\n# Example usage\nreservoir_list = [\"LAKE POWELL\", \"LAKE MEAD\", \"FLAMING GORGE RESERVOIR\"]\nexport_data_to_csv(reservoir_list, \"2020-01-01\", \"2020-12-31\", \"colorado_river_basin_evaporation_2020.csv\")\n</code></pre> <pre><code># Export data to a file\ncurl -X GET \"${BASE_URL}/timeseries/daily/reservoirs/daterange?RES_NAMES=LAKE%20POWELL,LAKE%20MEAD,FLAMING%20GORGE%20RESERVOIR&amp;datasets=nete-volume-calcs&amp;variables=NetE,E_volume&amp;start_date=2020-01-01&amp;end_date=2020-12-31&amp;units=metric&amp;output_format=csv\" \\\n     -H \"api-key: ${API_KEY}\" &gt; colorado_river_basin_evaporation_2020.csv\n</code></pre>"},{"location":"examples/#working-with-station-data","title":"Working with Station Data","text":"PythoncURL <pre><code>def get_station_data(station_names, start_date, end_date):\n    \"\"\"Get data for weather stations.\"\"\"\n    url = f\"{BASE_URL}/timeseries/stations/daterange\"\n    params = {\n        \"STA_NAMES\": \",\".join(station_names),\n        \"variables\": \"ATemp,RH,WS,WD\",\n        \"start_date\": start_date,\n        \"end_date\": end_date,\n        \"units\": \"metric\",\n        \"output_format\": \"json\"\n    }\n\n    response = requests.get(url, headers=HEADERS, params=params)\n\n    if response.status_code == 200:\n        return response.json()\n    else:\n        print(f\"Error: {response.status_code}\")\n        return None\n\n# Example usage\nstations = [\"LAKE MEAD_STATION\", \"LAKE POWELL_STATION\"]\nstation_data = get_station_data(stations, \"2020-06-01\", \"2020-06-30\")\n\n# Convert to DataFrame\ndf = pd.DataFrame(station_data)\ndf['date'] = pd.to_datetime(df['date'])\n\n# Plot temperature comparison between stations\npivot_df = df.pivot_table(index='date', columns='sta_name', values='ATemp')\n\nplt.figure(figsize=(12, 6))\nfor station in stations:\n    plt.plot(pivot_df.index, pivot_df[station], label=station)\n\nplt.title('Air Temperature Comparison Between Stations (June 2020)')\nplt.xlabel('Date')\nplt.ylabel('Air Temperature (\u00b0C)')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n</code></pre> <pre><code># Get station data\ncurl -X GET \"${BASE_URL}/timeseries/stations/daterange?STA_NAMES=LAKE%20MEAD_STATION,LAKE%20POWELL_STATION&amp;variables=ATemp,RH,WS,WD&amp;start_date=2020-06-01&amp;end_date=2020-06-30&amp;units=metric&amp;output_format=json\" \\\n     -H \"api-key: ${API_KEY}\"\n</code></pre>"},{"location":"examples/#gis-integration-using-geopandas","title":"GIS Integration (Using GeoPandas)","text":"PythoncURL <pre><code>import geopandas as gpd\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import Normalize\nfrom matplotlib.cm import ScalarMappable\n\ndef plot_reservoir_map(date):\n    \"\"\"Plot a map of reservoirs with evaporation values for a specific date.\"\"\"\n    # Get data for all reservoirs on a specific date\n    url = f\"{BASE_URL}/timeseries/daily/reservoirs/date\"\n    params = {\n        \"datasets\": \"nete-volume-calcs\",\n        \"variables\": \"NetE\",\n        \"date\": date,\n        \"units\": \"metric\",\n        \"output_format\": \"json\",\n        \"also_return\": \"latitude,longitude\"\n    }\n\n    response = requests.get(url, headers=HEADERS, params=params)\n\n    if response.status_code == 200:\n        data = response.json()\n        df = pd.DataFrame(data)\n\n        # Create GeoDataFrame\n        gdf = gpd.GeoDataFrame(\n            df,\n            geometry=gpd.points_from_xy(df.longitude, df.latitude),\n            crs=\"EPSG:4326\"\n        )\n\n        # Get US states outline for background\n        states = gpd.read_file('https://raw.githubusercontent.com/PublicaMundi/MappingAPI/master/data/geojson/us-states.json')\n        western_states = states[states['name'].isin([\n            'Washington', 'Oregon', 'California', 'Idaho', 'Nevada', 'Montana',\n            'Wyoming', 'Utah', 'Colorado', 'Arizona', 'New Mexico', 'Texas',\n            'North Dakota', 'South Dakota', 'Nebraska', 'Kansas', 'Oklahoma'\n        ])]\n\n        # Plot\n        fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n        western_states.boundary.plot(ax=ax, linewidth=1, color='gray')\n\n        # Plot points with color based on NetE value\n        scatter = ax.scatter(\n            gdf.geometry.x,\n            gdf.geometry.y,\n            c=gdf['NetE'],\n            cmap='YlOrRd',\n            s=50,\n            alpha=0.7,\n            edgecolor='black'\n        )\n\n        # Add colorbar\n        norm = Normalize(vmin=gdf['NetE'].min(), vmax=gdf['NetE'].max())\n        sm = ScalarMappable(norm=norm, cmap='YlOrRd')\n        sm.set_array([])\n        cbar = fig.colorbar(sm, ax=ax)\n        cbar.set_label('Net Evaporation (mm/day)')\n\n        # Add title and labels\n        plt.title(f'Reservoir Net Evaporation on {date}')\n        plt.xlabel('Longitude')\n        plt.ylabel('Latitude')\n\n        plt.tight_layout()\n        plt.show()\n\n        return gdf\n    else:\n        print(f\"Error: {response.status_code}\")\n        return None\n\n# Example usage\nreservoir_map = plot_reservoir_map(\"2020-07-15\")\n</code></pre> <pre><code># Get geospatial data for reservoirs on a specific date\ncurl -X GET \"${BASE_URL}/timeseries/daily/reservoirs/date?datasets=nete-volume-calcs&amp;variables=NetE&amp;date=2020-07-15&amp;units=metric&amp;output_format=json&amp;also_return=latitude,longitude\" \\\n     -H \"api-key: ${API_KEY}\"\n</code></pre> <p>These examples demonstrate common use cases for the Reservoir Evaporation API and provide a starting point for your own analysis. You can modify and extend these examples to suit your specific needs.</p>"},{"location":"faq/","title":"Frequently Asked Questions","text":"<p>This page addresses common questions about PhenoFetch and its usage.</p>"},{"location":"faq/#general-questions","title":"General Questions","text":""},{"location":"faq/#what-is-phenofetch","title":"What is PhenoFetch?","text":"<p>PhenoFetch is a command-line tool for downloading and analyzing PhenoCam data from NEON (National Ecological Observatory Network) sites. It simplifies the process of retrieving time-lapse images used for monitoring vegetation phenology.</p>"},{"location":"faq/#is-phenofetch-affiliated-with-neon-or-the-phenocam-network","title":"Is PhenoFetch affiliated with NEON or the PhenoCam Network?","text":"<p>No, PhenoFetch is not officially affiliated with the National Ecological Observatory Network (NEON) or the PhenoCam Network. It is an independent tool developed to facilitate access to publicly available PhenoCam data.</p>"},{"location":"faq/#what-license-is-phenofetch-released-under","title":"What license is PhenoFetch released under?","text":"<p>PhenoFetch is released under the Apache License 2.0.</p>"},{"location":"faq/#installation-questions","title":"Installation Questions","text":""},{"location":"faq/#what-are-the-system-requirements-for-phenofetch","title":"What are the system requirements for PhenoFetch?","text":"<p>PhenoFetch requires: - Python 3.9 or higher - Internet connection to download data - Sufficient disk space for downloaded images</p>"},{"location":"faq/#why-am-i-getting-an-error-during-installation","title":"Why am I getting an error during installation?","text":"<p>Common installation issues include: - Insufficient permissions (try using <code>pip install --user phenofetch</code>) - Outdated pip (try <code>pip install --upgrade pip</code> first) - Missing dependencies (ensure you have all required packages)</p>"},{"location":"faq/#can-i-use-phenofetch-on-windowsmaclinux","title":"Can I use PhenoFetch on Windows/Mac/Linux?","text":"<p>Yes, PhenoFetch is compatible with all major operating systems including Windows, macOS, and Linux.</p>"},{"location":"faq/#usage-questions","title":"Usage Questions","text":""},{"location":"faq/#what-is-a-neon-site-code","title":"What is a NEON site code?","text":"<p>A NEON site code is a unique identifier for each site in the National Ecological Observatory Network. Examples include \"HARV\" for Harvard Forest, \"ABBY\" for Abby Road, etc. You can see all available site codes using the <code>phenofetch sites</code> command.</p>"},{"location":"faq/#what-is-a-neon-product-id","title":"What is a NEON product ID?","text":"<p>A NEON product ID identifies a specific data product. For PhenoCam images, the product ID is typically \"DP1.00033\".</p>"},{"location":"faq/#how-much-disk-space-will-the-downloaded-data-require","title":"How much disk space will the downloaded data require?","text":"<p>The disk space required depends on the site and date range. Full-resolution images are typically 2-4 MB each, and there are usually 24-48 images per day. You can use the <code>estimate</code> command to calculate the expected download size before committing to a full download.</p>"},{"location":"faq/#are-the-downloaded-images-georeferenced","title":"Are the downloaded images georeferenced?","text":"<p>PhenoCam images are not georeferenced in the traditional GIS sense. However, each site has fixed latitude and longitude coordinates which are available in the site metadata.</p>"},{"location":"faq/#data-questions","title":"Data Questions","text":""},{"location":"faq/#what-types-of-files-does-phenofetch-download","title":"What types of files does PhenoFetch download?","text":"<p>PhenoFetch can download three types of files: - Full-resolution images (.jpg) - Thumbnail images (.jpg) - Metadata files (.meta)</p>"},{"location":"faq/#what-information-is-contained-in-the-metadata-files","title":"What information is contained in the metadata files?","text":"<p>Metadata files typically include: - Camera information - Capture time and conditions - Site information - Technical settings (exposure, white balance, etc.)</p>"},{"location":"faq/#how-frequently-are-images-captured-at-neon-phenocam-sites","title":"How frequently are images captured at NEON PhenoCam sites?","text":"<p>Most NEON PhenoCam sites capture images every 30 minutes during daylight hours, but this can vary by site. Some sites may have more frequent or less frequent capture intervals.</p>"},{"location":"faq/#what-file-organization-should-i-expect-in-the-downloaded-data","title":"What file organization should I expect in the downloaded data?","text":"<p>Downloaded files are organized into three subdirectories: - <code>full_res/</code>: Contains full-resolution images - <code>thumbnails/</code>: Contains thumbnail images - <code>meta/</code>: Contains metadata files</p> <p>The original filenames are preserved.</p>"},{"location":"faq/#performance-questions","title":"Performance Questions","text":""},{"location":"faq/#how-can-i-speed-up-downloads","title":"How can I speed up downloads?","text":"<p>To speed up downloads: - Increase the batch size (<code>--batch-size</code> option) - Increase concurrency if you have a fast connection (<code>--concurrency</code> option) - Ensure you have a stable internet connection - Download smaller date ranges at a time</p>"},{"location":"faq/#why-are-my-downloads-slow-or-failing","title":"Why are my downloads slow or failing?","text":"<p>Possible reasons include: - Slow or unstable internet connection - Server-side limitations - Too many concurrent connections - High server load</p> <p>Try reducing concurrency, using smaller batch sizes, or retrying during off-peak hours.</p>"},{"location":"faq/#how-does-phenofetch-determine-the-optimal-concurrency","title":"How does PhenoFetch determine the optimal concurrency?","text":"<p>PhenoFetch automatically determines the optimal concurrency based on your system's CPU cores and available memory. This auto-tuning helps ensure efficient downloads without overwhelming your system or the server.</p>"},{"location":"faq/#troubleshooting","title":"Troubleshooting","text":""},{"location":"faq/#error-no-data-found-for-the-specified-date-range","title":"Error: \"No data found for the specified date range\"","text":"<p>This error occurs when there are no PhenoCam images available for the site and date range you specified. Use the <code>stats</code> command to see what data is available for your site of interest.</p>"},{"location":"faq/#error-site-code-not-found-in-available-sites","title":"Error: \"Site code not found in available sites\"","text":"<p>This error means you've specified an invalid site code. Use the <code>phenofetch sites</code> command to see a list of all valid site codes.</p>"},{"location":"faq/#downloads-start-but-then-stall-or-time-out","title":"Downloads start but then stall or time out","text":"<p>If downloads stall: - Try increasing the timeout value (<code>--timeout</code> option) - Reduce concurrency (<code>--concurrency</code> option) - Try smaller batch sizes - Check your internet connection - Retry during off-peak hours</p>"},{"location":"faq/#some-files-failed-to-download","title":"Some files failed to download","text":"<p>Failed downloads are reported at the end of the process. Common causes include: - Temporary server issues - Network interruptions - Files that exist on the server index but aren't actually available</p> <p>You can retry the download for the same date range; PhenoFetch will skip files that were already successfully downloaded.</p>"},{"location":"installation/","title":"Installation","text":"<p>PhenoFetch can be installed easily using pip, or directly from the source code.</p>"},{"location":"installation/#prerequisites","title":"Prerequisites","text":"<p>Before installing PhenoFetch, ensure you have the following prerequisites:</p> <ul> <li>Python 3.9 or higher</li> <li>pip (Python package installer)</li> </ul>"},{"location":"installation/#install-via-pip","title":"Install via pip","text":"<p>The simplest way to install PhenoFetch is through pip:</p> <pre><code>pip install phenofetch\n</code></pre> <p>To upgrade to the latest version:</p> <pre><code>pip install --upgrade phenofetch\n</code></pre>"},{"location":"installation/#install-from-source","title":"Install from source","text":"<p>If you prefer to install from source or want to contribute to the development:</p> <ol> <li> <p>Clone the repository:    <pre><code>git clone https://github.com/samapriya/phenofetch.git\ncd phenofetch\n</code></pre></p> </li> <li> <p>Install in development mode:    <pre><code>pip install -e .\n</code></pre></p> </li> </ol>"},{"location":"installation/#dependencies","title":"Dependencies","text":"<p>PhenoFetch relies on the following Python packages (these will be automatically installed with pip):</p> <ul> <li>requests &gt;= 2.28.0</li> <li>beautifulsoup4 &gt;= 4.11.0</li> <li>aiofiles &gt;= 0.8.0</li> <li>aiohttp &gt;= 3.8.0</li> <li>psutil &gt;= 5.9.0</li> <li>rich &gt;= 12.0.0</li> <li>tqdm &gt;= 4.64.0</li> <li>colorama &gt;= 0.4.4</li> </ul>"},{"location":"installation/#verification","title":"Verification","text":"<p>To verify that PhenoFetch was installed correctly, run:</p> <pre><code>phenofetch --help\n</code></pre> <p>You should see the help menu with all available commands.</p>"},{"location":"installation/#common-installation-issues","title":"Common Installation Issues","text":""},{"location":"installation/#permission-denied-errors","title":"Permission denied errors","text":"<p>If you encounter permission errors while installing, try using:</p> <pre><code>pip install --user phenofetch\n</code></pre>"},{"location":"installation/#package-not-found-after-installation","title":"Package not found after installation","text":"<p>If the <code>phenofetch</code> command is not found after installation, ensure that your Python scripts directory is in your system PATH.</p> <p>For most systems, you can check where pip installs executables with:</p> <pre><code>pip show phenofetch\n</code></pre> <p>Then add the relevant bin directory to your PATH if necessary.</p>"},{"location":"installation/#incompatible-python-version","title":"Incompatible Python version","text":"<p>PhenoFetch requires Python 3.9 or higher. If you're using an older version, you'll need to upgrade your Python installation.</p>"},{"location":"license/","title":"License","text":"<p> <pre><code>Apache License\nVersion 2.0, January 2004\nhttp://www.apache.org/licenses/\n</code></pre> </p> <p>TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION</p> <ol> <li> <p>Definitions.</p> <p>\"License\" shall mean the terms and conditions for use, reproduction,   and distribution as defined by Sections 1 through 9 of this document.</p> <p>\"Licensor\" shall mean the copyright owner or entity authorized by   the copyright owner that is granting the License.</p> <p>\"Legal Entity\" shall mean the union of the acting entity and all   other entities that control, are controlled by, or are under common   control with that entity. For the purposes of this definition,   \"control\" means (i) the power, direct or indirect, to cause the   direction or management of such entity, whether by contract or   otherwise, or (ii) ownership of fifty percent (50%) or more of the   outstanding shares, or (iii) beneficial ownership of such entity.</p> <p>\"You\" (or \"Your\") shall mean an individual or Legal Entity   exercising permissions granted by this License.</p> <p>\"Source\" form shall mean the preferred form for making modifications,   including but not limited to software source code, documentation   source, and configuration files.</p> <p>\"Object\" form shall mean any form resulting from mechanical   transformation or translation of a Source form, including but   not limited to compiled object code, generated documentation,   and conversions to other media types.</p> <p>\"Work\" shall mean the work of authorship, whether in Source or   Object form, made available under the License, as indicated by a   copyright notice that is included in or attached to the work   (an example is provided in the Appendix below).</p> <p>\"Derivative Works\" shall mean any work, whether in Source or Object   form, that is based on (or derived from) the Work and for which the   editorial revisions, annotations, elaborations, or other modifications   represent, as a whole, an original work of authorship. For the purposes   of this License, Derivative Works shall not include works that remain   separable from, or merely link (or bind by name) to the interfaces of,   the Work and Derivative Works thereof.</p> <p>\"Contribution\" shall mean any work of authorship, including   the original version of the Work and any modifications or additions   to that Work or Derivative Works thereof, that is intentionally   submitted to Licensor for inclusion in the Work by the copyright owner   or by an individual or Legal Entity authorized to submit on behalf of   the copyright owner. For the purposes of this definition, \"submitted\"   means any form of electronic, verbal, or written communication sent   to the Licensor or its representatives, including but not limited to   communication on electronic mailing lists, source code control systems,   and issue tracking systems that are managed by, or on behalf of, the   Licensor for the purpose of discussing and improving the Work, but   excluding communication that is conspicuously marked or otherwise   designated in writing by the copyright owner as \"Not a Contribution.\"</p> <p>\"Contributor\" shall mean Licensor and any individual or Legal Entity   on behalf of whom a Contribution has been received by Licensor and   subsequently incorporated within the Work.</p> </li> <li> <p>Grant of Copyright License. Subject to the terms and conditions of       this License, each Contributor hereby grants to You a perpetual,       worldwide, non-exclusive, no-charge, royalty-free, irrevocable       copyright license to reproduce, prepare Derivative Works of,       publicly display, publicly perform, sublicense, and distribute the       Work and such Derivative Works in Source or Object form.</p> </li> <li> <p>Grant of Patent License. Subject to the terms and conditions of       this License, each Contributor hereby grants to You a perpetual,       worldwide, non-exclusive, no-charge, royalty-free, irrevocable       (except as stated in this section) patent license to make, have made,       use, offer to sell, sell, import, and otherwise transfer the Work,       where such license applies only to those patent claims licensable       by such Contributor that are necessarily infringed by their       Contribution(s) alone or by combination of their Contribution(s)       with the Work to which such Contribution(s) was submitted. If You       institute patent litigation against any entity (including a       cross-claim or counterclaim in a lawsuit) alleging that the Work       or a Contribution incorporated within the Work constitutes direct       or contributory patent infringement, then any patent licenses       granted to You under this License for that Work shall terminate       as of the date such litigation is filed.</p> </li> <li> <p>Redistribution. You may reproduce and distribute copies of the       Work or Derivative Works thereof in any medium, with or without       modifications, and in Source or Object form, provided that You       meet the following conditions:</p> <p>(a) You must give any other recipients of the Work or       Derivative Works a copy of this License; and</p> <p>(b) You must cause any modified files to carry prominent notices       stating that You changed the files; and</p> <p>\u00a9 You must retain, in the Source form of any Derivative Works       that You distribute, all copyright, patent, trademark, and       attribution notices from the Source form of the Work,       excluding those notices that do not pertain to any part of       the Derivative Works; and</p> <p>(d) If the Work includes a \"NOTICE\" text file as part of its       distribution, then any Derivative Works that You distribute must       include a readable copy of the attribution notices contained       within such NOTICE file, excluding those notices that do not       pertain to any part of the Derivative Works, in at least one       of the following places: within a NOTICE text file distributed       as part of the Derivative Works; within the Source form or       documentation, if provided along with the Derivative Works; or,       within a display generated by the Derivative Works, if and       wherever such third-party notices normally appear. The contents       of the NOTICE file are for informational purposes only and       do not modify the License. You may add Your own attribution       notices within Derivative Works that You distribute, alongside       or as an addendum to the NOTICE text from the Work, provided       that such additional attribution notices cannot be construed       as modifying the License.</p> <p>You may add Your own copyright statement to Your modifications and   may provide additional or different license terms and conditions   for use, reproduction, or distribution of Your modifications, or   for any such Derivative Works as a whole, provided Your use,   reproduction, and distribution of the Work otherwise complies with   the conditions stated in this License.</p> </li> <li> <p>Submission of Contributions. Unless You explicitly state otherwise,       any Contribution intentionally submitted for inclusion in the Work       by You to the Licensor shall be under the terms and conditions of       this License, without any additional terms or conditions.       Notwithstanding the above, nothing herein shall supersede or modify       the terms of any separate license agreement you may have executed       with Licensor regarding such Contributions.</p> </li> <li> <p>Trademarks. This License does not grant permission to use the trade       names, trademarks, service marks, or product names of the Licensor,       except as required for reasonable and customary use in describing the       origin of the Work and reproducing the content of the NOTICE file.</p> </li> <li> <p>Disclaimer of Warranty. Unless required by applicable law or       agreed to in writing, Licensor provides the Work (and each       Contributor provides its Contributions) on an \"AS IS\" BASIS,       WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or       implied, including, without limitation, any warranties or conditions       of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A       PARTICULAR PURPOSE. You are solely responsible for determining the       appropriateness of using or redistributing the Work and assume any       risks associated with Your exercise of permissions under this License.</p> </li> <li> <p>Limitation of Liability. In no event and under no legal theory,       whether in tort (including negligence), contract, or otherwise,       unless required by applicable law (such as deliberate and grossly       negligent acts) or agreed to in writing, shall any Contributor be       liable to You for damages, including any direct, indirect, special,       incidental, or consequential damages of any character arising as a       result of this License or out of the use or inability to use the       Work (including but not limited to damages for loss of goodwill,       work stoppage, computer failure or malfunction, or any and all       other commercial damages or losses), even if such Contributor       has been advised of the possibility of such damages.</p> </li> <li> <p>Accepting Warranty or Additional Liability. While redistributing       the Work or Derivative Works thereof, You may choose to offer,       and charge a fee for, acceptance of support, warranty, indemnity,       or other liability obligations and/or rights consistent with this       License. However, in accepting such obligations, You may act only       on Your own behalf and on Your sole responsibility, not on behalf       of any other Contributor, and only if You agree to indemnify,       defend, and hold each Contributor harmless for any liability       incurred by, or claims asserted against, such Contributor by reason       of your accepting any such warranty or additional liability.</p> </li> </ol> <p>END OF TERMS AND CONDITIONS</p> <p>APPENDIX: How to apply the Apache License to your work.</p> <pre><code>  To apply the Apache License to your work, attach the following\n  boilerplate notice, with the fields enclosed by brackets \"{}\"\n  replaced with your own identifying information. (Don't include\n  the brackets!)  The text should be enclosed in the appropriate\n  comment syntax for the file format. We also recommend that a\n  file or class name and description of purpose be included on the\n  same \"printed page\" as the copyright notice for easier\n  identification within third-party archives.\n</code></pre> <p>Copyright {2025} {Samapriya Roy}</p> <p>Licensed under the Apache License, Version 2.0 (the \"License\");    you may not use this file except in compliance with the License.    You may obtain a copy of the License at</p> <pre><code>   http://www.apache.org/licenses/LICENSE-2.0\n</code></pre> <p>Unless required by applicable law or agreed to in writing, software    distributed under the License is distributed on an \"AS IS\" BASIS,    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.    See the License for the specific language governing permissions and    limitations under the License.</p>"},{"location":"usage/","title":"Usage","text":"<p>PhenoFetch provides a straightforward command-line interface for downloading and analyzing PhenoCam data. This page covers the basic usage patterns and common workflows.</p>"},{"location":"usage/#command-structure","title":"Command Structure","text":"<p>All PhenoFetch commands follow this basic structure:</p> <pre><code>phenofetch [command] [options]\n</code></pre> <p>The main commands are:</p> <ul> <li><code>sites</code> - List all available PhenoCam sites</li> <li><code>stats</code> - Display statistics for a site</li> <li><code>estimate</code> - Estimate download size for a date range</li> <li><code>download</code> - Download data for a specific site and date range</li> </ul>"},{"location":"usage/#getting-help","title":"Getting Help","text":"<p>To see all available commands and options:</p> <pre><code>phenofetch --help\n</code></pre> <p>For help with a specific command:</p> <pre><code>phenofetch [command] --help\n</code></pre>"},{"location":"usage/#common-arguments","title":"Common Arguments","text":"<p>Many commands share common arguments:</p> <ul> <li><code>--site</code> - NEON site code (e.g., ABBY, BART)</li> <li><code>--product</code> - NEON product ID (e.g., DP1.00033)</li> <li><code>--start-date</code> - Start date in YYYY-MM-DD format</li> <li><code>--end-date</code> - End date in YYYY-MM-DD format</li> </ul>"},{"location":"usage/#basic-workflow","title":"Basic Workflow","text":"<p>A typical workflow with PhenoFetch might look like this:</p> <ol> <li> <p>Discover available sites:    <pre><code>phenofetch sites\n</code></pre></p> </li> <li> <p>Check site statistics to understand data availability:    <pre><code>phenofetch stats --site HARV --product DP1.00033\n</code></pre></p> </li> <li> <p>Estimate download size before committing to a large download:    <pre><code>phenofetch estimate --site ABBY --product DP1.00033 --start-date 2022-01-01 --end-date 2022-01-31\n</code></pre></p> </li> <li> <p>Download the data:    <pre><code>phenofetch download --site ABBY --product DP1.00033 --start-date 2022-01-01 --end-date 2022-01-31 --download --output-dir ./my_phenocam_data\n</code></pre></p> </li> </ol>"},{"location":"usage/#understanding-download-output","title":"Understanding Download Output","text":"<p>When downloading data, PhenoFetch will create a directory structure that preserves the organization of the files:</p> <pre><code>output_dir/\n\u251c\u2500\u2500 full_res/\n\u2502   \u251c\u2500\u2500 image1.jpg\n\u2502   \u251c\u2500\u2500 image2.jpg\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 thumbnails/\n\u2502   \u251c\u2500\u2500 thumb1.jpg\n\u2502   \u251c\u2500\u2500 thumb2.jpg\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 meta/\n    \u251c\u2500\u2500 metadata1.meta\n    \u251c\u2500\u2500 metadata2.meta\n    \u2514\u2500\u2500 ...\n</code></pre> <ul> <li><code>full_res/</code> - Contains full-resolution images</li> <li><code>thumbnails/</code> - Contains thumbnail images</li> <li><code>meta/</code> - Contains metadata files</li> </ul>"},{"location":"usage/#managing-downloads","title":"Managing Downloads","text":"<p>PhenoFetch provides several options to manage downloads effectively:</p> <ul> <li> <p>Batch size: Control how many files are processed in each batch   <pre><code>--batch-size 100\n</code></pre></p> </li> <li> <p>Concurrency: Set maximum number of concurrent downloads (by default, this is auto-determined based on your system resources)   <pre><code>--concurrency 8\n</code></pre></p> </li> <li> <p>Timeout: Set connection timeout in seconds   <pre><code>--timeout 60\n</code></pre></p> </li> </ul>"},{"location":"usage/#preview-mode","title":"Preview Mode","text":"<p>To see what files would be downloaded without actually downloading them:</p> <pre><code>phenofetch download --site ABBY --product DP1.00033 --start-date 2022-01-01 --end-date 2022-01-31\n</code></pre> <p>Note that omitting the <code>--download</code> flag will only show a summary of available files.</p>"},{"location":"endpoints/info-endpoints/","title":"Info Endpoints","text":"<p>The Info/Help endpoints provide information about the available data in the API, including datasets, variables, reservoirs, stations, and date ranges. These endpoints are useful for discovering what data is available and how to access it.</p>"},{"location":"endpoints/info-endpoints/#list-available-datasets","title":"List Available Datasets","text":"<p>Lists all available datasets in the API.</p> <pre><code>import requests\n\nurl = \"https://operevap.dri.edu/info/list_datasets\"\nheaders = {\n    \"api-key\": \"YOUR_API_KEY\"\n}\nparams = {\n    \"output_format\": \"json\"  # or \"csv\"\n}\n\nresponse = requests.get(url, headers=headers, params=params)\ndata = response.json()\nprint(data)\n</code></pre>"},{"location":"endpoints/info-endpoints/#parameters","title":"Parameters","text":"Parameter Type Description Default output_format string Response format (json or csv) json"},{"location":"endpoints/info-endpoints/#response","title":"Response","text":"<p>Returns a list of dataset names that can be used as the <code>dataset</code> parameter in other API requests.</p>"},{"location":"endpoints/info-endpoints/#list-available-variables","title":"List Available Variables","text":"<p>Lists available variables for a specified dataset.</p> <pre><code>import requests\n\nurl = \"https://operevap.dri.edu/info/list_variables\"\nheaders = {\n    \"api-key\": \"YOUR_API_KEY\"\n}\nparams = {\n    \"output_format\": \"json\",  # or \"csv\"\n    \"dataset\": \"nete-volume-calcs\"  # Dataset name\n}\n\nresponse = requests.get(url, headers=headers, params=params)\ndata = response.json()\nprint(data)\n</code></pre>"},{"location":"endpoints/info-endpoints/#parameters_1","title":"Parameters","text":"Parameter Type Description Default output_format string Response format (json or csv) json dataset string Dataset name (rtma, res, lem, nete-volume-calcs) nete-volume-calcs"},{"location":"endpoints/info-endpoints/#response_1","title":"Response","text":"<p>Returns a list of dictionaries containing variable information. The <code>api_name</code> field in each dictionary can be used as the <code>variable</code> parameter in other API requests.</p>"},{"location":"endpoints/info-endpoints/#list-date-range","title":"List Date Range","text":"<p>Lists the minimum and maximum dates available for a dataset and variable.</p> <pre><code>import requests\n\nurl = \"https://operevap.dri.edu/info/list_dates\"\nheaders = {\n    \"api-key\": \"YOUR_API_KEY\"\n}\nparams = {\n    \"output_format\": \"json\",  # or \"csv\"\n    \"dataset\": \"nete-volume-calcs\",\n    \"variable\": \"NetE\"\n}\n\nresponse = requests.get(url, headers=headers, params=params)\ndata = response.json()\nprint(data)\n</code></pre>"},{"location":"endpoints/info-endpoints/#parameters_2","title":"Parameters","text":"Parameter Type Description Default output_format string Response format (json or csv) json dataset string Dataset name (rtma, res, lem, nete-volume-calcs) nete-volume-calcs variable string Variable name (see list_variables endpoint) NetE"},{"location":"endpoints/info-endpoints/#response_2","title":"Response","text":"<p>Returns a list containing the start date and end date for the specified dataset and variable.</p>"},{"location":"endpoints/info-endpoints/#list-reservoir-names","title":"List Reservoir Names","text":"<p>Lists available reservoir IDs (RES_NAME) that can be used in other API requests.</p> <pre><code>import requests\n\nurl = \"https://operevap.dri.edu/info/list_RES_NAMES\"\nheaders = {\n    \"api-key\": \"YOUR_API_KEY\"\n}\nparams = {\n    \"output_format\": \"json\"  # or \"csv\"\n}\n\n# Without shapefile\nresponse = requests.post(url, headers=headers, params=params)\ndata = response.json()\nprint(data)\n\n# With shapefile (if needed)\nfiles = {\n    'shapefile_shp': open('your_shapefile.shp', 'rb'),\n    'shapefile_dbf': open('your_shapefile.dbf', 'rb'),\n    'shapefile_prj': open('your_shapefile.prj', 'rb'),\n    'shapefile_shx': open('your_shapefile.shx', 'rb')\n}\n\nresponse = requests.post(url, headers=headers, params=params, files=files)\ndata = response.json()\nprint(data)\n</code></pre>"},{"location":"endpoints/info-endpoints/#parameters_3","title":"Parameters","text":"Parameter Type Description Default output_format string Response format (json or csv) json shapefile_shp file Optional .shp file to filter reservoirs by location shapefile_dbf file Optional .dbf file to filter reservoirs by location shapefile_prj file Optional .prj file to filter reservoirs by location shapefile_shx file Optional .shx file to filter reservoirs by location"},{"location":"endpoints/info-endpoints/#response_3","title":"Response","text":"<p>Returns a list of reservoir names that can be used as the <code>RES_NAMES</code> parameter in metadata and timeseries API requests.</p>"},{"location":"endpoints/info-endpoints/#notes","title":"Notes","text":"<p>If shapefiles are uploaded, only reservoirs within the shapefile bounds will be returned.</p>"},{"location":"endpoints/info-endpoints/#list-station-names","title":"List Station Names","text":"<p>Lists available station IDs (STA_NAME) that can be used in other API requests.</p> <pre><code>import requests\n\nurl = \"https://operevap.dri.edu/info/list_STA_NAMES\"\nheaders = {\n    \"api-key\": \"YOUR_API_KEY\"\n}\nparams = {\n    \"output_format\": \"json\"  # or \"csv\"\n}\n\n# Without shapefile\nresponse = requests.post(url, headers=headers, params=params)\ndata = response.json()\nprint(data)\n\n# With shapefile (if needed)\nfiles = {\n    'shapefile_shp': open('your_shapefile.shp', 'rb'),\n    'shapefile_dbf': open('your_shapefile.dbf', 'rb'),\n    'shapefile_prj': open('your_shapefile.prj', 'rb'),\n    'shapefile_shx': open('your_shapefile.shx', 'rb')\n}\n\nresponse = requests.post(url, headers=headers, params=params, files=files)\ndata = response.json()\nprint(data)\n</code></pre>"},{"location":"endpoints/info-endpoints/#parameters_4","title":"Parameters","text":"Parameter Type Description Default output_format string Response format (json or csv) json shapefile_shp file Optional .shp file to filter stations by location shapefile_dbf file Optional .dbf file to filter stations by location shapefile_prj file Optional .prj file to filter stations by location shapefile_shx file Optional .shx file to filter stations by location"},{"location":"endpoints/info-endpoints/#response_4","title":"Response","text":"<p>Returns a list of station names that can be used as the <code>STA_NAMES</code> parameter in metadata and timeseries API requests.</p>"},{"location":"endpoints/info-endpoints/#notes_1","title":"Notes","text":"<p>If shapefiles are uploaded, only stations within the shapefile bounds will be returned.</p>"},{"location":"endpoints/info-endpoints/#list-station-variables","title":"List Station Variables","text":"<p>Lists available variables for stations.</p> <pre><code>import requests\n\nurl = \"https://operevap.dri.edu/info/list_stations_variables\"\nheaders = {\n    \"api-key\": \"YOUR_API_KEY\"\n}\nparams = {\n    \"output_format\": \"json\",  # or \"csv\"\n    \"STA_NAMES\": \"ALL_STATIONS\"  # or comma-separated list of station names\n}\n\nresponse = requests.get(url, headers=headers, params=params)\ndata = response.json()\nprint(data)\n</code></pre>"},{"location":"endpoints/info-endpoints/#parameters_5","title":"Parameters","text":"Parameter Type Description Default output_format string Response format (json or csv) json STA_NAMES string One or more station names (comma-separated), or ALL_STATIONS ALL_STATIONS"},{"location":"endpoints/info-endpoints/#response_5","title":"Response","text":"<p>Returns a list of dictionaries containing variable information. The <code>api_name</code> field in each dictionary can be used as the <code>variable</code> parameter in other API requests.</p>"},{"location":"endpoints/info-endpoints/#list-station-date-range","title":"List Station Date Range","text":"<p>Lists the minimum and maximum dates available for stations in the database.</p> <pre><code>import requests\n\nurl = \"https://operevap.dri.edu/info/list_stations_dates\"\nheaders = {\n    \"api-key\": \"YOUR_API_KEY\"\n}\nparams = {\n    \"output_format\": \"json\",  # or \"csv\"\n    \"STA_NAMES\": \"ALL_STATIONS\"  # or comma-separated list of station names\n}\n\nresponse = requests.get(url, headers=headers, params=params)\ndata = response.json()\nprint(data)\n</code></pre>"},{"location":"endpoints/info-endpoints/#parameters_6","title":"Parameters","text":"Parameter Type Description Default output_format string Response format (json or csv) json STA_NAMES string One or more station names (comma-separated), or ALL_STATIONS ALL_STATIONS"},{"location":"endpoints/info-endpoints/#response_6","title":"Response","text":"<p>Returns a list containing the start date and end date for the specified stations.</p>"},{"location":"endpoints/metadata-endpoints/","title":"Metadata Endpoints","text":"<p>The metadata endpoints provide information about the reservoirs and stations available in the API. This metadata includes details such as location, physical characteristics, and other attributes.</p>"},{"location":"endpoints/metadata-endpoints/#reservoir-metadata","title":"Reservoir Metadata","text":"<p>Retrieves metadata for one or more reservoirs.</p> <pre><code>import requests\n\nurl = \"https://operevap.dri.edu/metadata/reservoirs\"\nheaders = {\n    \"api-key\": \"YOUR_API_KEY\"\n}\nparams = {\n    \"RES_NAMES\": \"LAKE ALICE,LAKE ESTES\",\n    \"output_format\": \"json\"\n}\n\nresponse = requests.get(url, headers=headers, params=params)\ndata = response.json()\nprint(data)\n</code></pre>"},{"location":"endpoints/metadata-endpoints/#parameters","title":"Parameters","text":"Parameter Type Description Default output_format string Response format (json or csv) json RES_NAMES string One or more reservoir names (comma-separated) LAKE ALICE, LAKE ESTES"},{"location":"endpoints/metadata-endpoints/#response","title":"Response","text":"<p>Returns a list of dictionaries containing metadata information for the specified reservoirs. The metadata includes attributes such as:</p> <ul> <li>Geographic coordinates (latitude, longitude)</li> <li>Physical characteristics (area, depth, etc.)</li> <li>Administrative information</li> <li>Quality flags (qflag)</li> <li>And other attributes</li> </ul>"},{"location":"endpoints/metadata-endpoints/#notes","title":"Notes","text":"<p>Use the <code>/info/list_RES_NAMES</code> endpoint to discover available reservoir names.</p>"},{"location":"endpoints/metadata-endpoints/#station-metadata","title":"Station Metadata","text":"<p>Retrieves metadata for one or more stations.</p> <pre><code>import requests\n\nurl = \"https://operevap.dri.edu/metadata/stations\"\nheaders = {\n    \"api-key\": \"YOUR_API_KEY\"\n}\nparams = {\n    \"STA_NAMES\": \"ABERDEEN_STATION,ABIQUIU DAM_STATION\",\n    \"output_format\": \"json\"\n}\n\nresponse = requests.get(url, headers=headers, params=params)\ndata = response.json()\nprint(data)\n</code></pre>"},{"location":"endpoints/metadata-endpoints/#parameters_1","title":"Parameters","text":"Parameter Type Description Default output_format string Response format (json or csv) json STA_NAMES string One or more station names (comma-separated) ABERDEEN_STATION, ABIQUIU DAM_STATION"},{"location":"endpoints/metadata-endpoints/#response_1","title":"Response","text":"<p>Returns a list of dictionaries containing metadata information for the specified stations. The metadata includes attributes such as:</p> <ul> <li>Geographic coordinates (latitude, longitude)</li> <li>Station type</li> <li>Operational status</li> <li>Associated reservoir (if applicable)</li> <li>Quality flags (qflag)</li> <li>And other attributes</li> </ul>"},{"location":"endpoints/metadata-endpoints/#notes_1","title":"Notes","text":"<p>Use the <code>/info/list_STA_NAMES</code> endpoint to discover available station names.</p>"},{"location":"endpoints/metadata-endpoints/#using-metadata-in-other-requests","title":"Using Metadata in Other Requests","text":"<p>The metadata attributes can be included in timeseries responses by using the <code>also_return</code> parameter in timeseries requests. For example:</p> <pre><code>import requests\n\nurl = \"https://operevap.dri.edu/timeseries/daily/reservoirs/daterange\"\nheaders = {\n    \"api-key\": \"YOUR_API_KEY\"\n}\nparams = {\n    \"RES_NAMES\": \"LAKE ALICE\",\n    \"datasets\": \"nete-volume-calcs\",\n    \"variables\": \"NetE,E_volume\",\n    \"start_date\": \"2020-01-01\",\n    \"end_date\": \"2020-01-31\",\n    \"units\": \"metric\",\n    \"also_return\": \"qflag\",\n    \"output_format\": \"json\"\n}\n\nresponse = requests.get(url, headers=headers, params=params)\ndata = response.json()\nprint(data)\n</code></pre> <p>This is useful for understanding the quality or context of the data returned in timeseries responses.</p>"},{"location":"endpoints/timeseries-endpoints/","title":"Timeseries Endpoints","text":"<p>The timeseries endpoints provide access to time-based data for reservoirs and stations. These endpoints are divided into two categories:</p> <ol> <li>Reservoir timeseries data</li> <li>Station timeseries data</li> </ol> <p>Each category has endpoints for retrieving data over a date range or for a single date.</p>"},{"location":"endpoints/timeseries-endpoints/#reservoir-timeseries-data-date-range","title":"Reservoir Timeseries Data (Date Range)","text":"<p>Retrieves timeseries data for one or more reservoirs over a specified date range.</p> <pre><code>import requests\n\nurl = \"https://operevap.dri.edu/timeseries/daily/reservoirs/daterange\"\nheaders = {\n    \"api-key\": \"YOUR_API_KEY\"\n}\nparams = {\n    \"RES_NAMES\": \"LAKE ALICE\",\n    \"datasets\": \"nete-volume-calcs\",\n    \"variables\": \"NetE,E_volume\",\n    \"start_date\": \"2020-01-01\",\n    \"end_date\": \"2020-01-31\",\n    \"units\": \"metric\",\n    \"output_format\": \"json\"\n}\n\nresponse = requests.get(url, headers=headers, params=params)\ndata = response.json()\nprint(data)\n</code></pre>"},{"location":"endpoints/timeseries-endpoints/#parameters","title":"Parameters","text":"Parameter Type Description Default RES_NAMES string One or more reservoir names (comma-separated) LAKE ALICE, LAKE ESTES datasets string One or more datasets (comma-separated) rtma, res, lem, nete-volume-calcs variables string One or more variables (comma-separated) pr, tmmx_c, tmmn_c, vpd_kpa, vs2m, srad, etr, eto, th, sph_kgkg, pres_pa, stage_m, area_m2, depth_m, E_hs, E_nhs, Rn, Tw, Tw0, Fetch, Lerr, NetE, E_volume, NetE_volume units string Units for returned data (english or metric) metric start_date string Start date (yyyy-mm-dd) 2020-01-01 end_date string End date (yyyy-mm-dd) 2020-01-31 also_return string Additional metadata attributes to include in response output_format string Response format (json or csv) json"},{"location":"endpoints/timeseries-endpoints/#response","title":"Response","text":"<p>Returns a list of dictionaries containing timeseries data for the specified reservoirs, datasets, variables, and date range.</p>"},{"location":"endpoints/timeseries-endpoints/#notes","title":"Notes","text":"<ul> <li>Use the <code>/info/list_RES_NAMES</code> endpoint to discover available reservoir names.</li> <li>Use the <code>/info/list_variables</code> endpoint to discover available variables for each dataset.</li> <li>Use the <code>/info/list_dates</code> endpoint to discover the valid date range for each dataset and variable.</li> </ul>"},{"location":"endpoints/timeseries-endpoints/#reservoir-timeseries-data-single-date","title":"Reservoir Timeseries Data (Single Date)","text":"<p>Retrieves timeseries data for all reservoirs on a single date.</p> <pre><code>import requests\n\nurl = \"https://operevap.dri.edu/timeseries/daily/reservoirs/date\"\nheaders = {\n    \"api-key\": \"YOUR_API_KEY\"\n}\nparams = {\n    \"datasets\": \"nete-volume-calcs\",\n    \"variables\": \"NetE,E_volume\",\n    \"date\": \"2020-01-01\",\n    \"units\": \"metric\",\n    \"output_format\": \"json\"\n}\n\nresponse = requests.get(url, headers=headers, params=params)\ndata = response.json()\nprint(data)\n</code></pre>"},{"location":"endpoints/timeseries-endpoints/#parameters_1","title":"Parameters","text":"Parameter Type Description Default datasets string One or more datasets (comma-separated) rtma, res, lem, nete-volume-calcs variables string One or more variables (comma-separated) pr, tmmx_c, tmmn_c, vpd_kpa, vs2m, srad, etr, eto, th, sph_kgkg, pres_pa, stage_m, area_m2, depth_m, E_hs, E_nhs, Rn, Tw, Tw0, Fetch, Lerr, NetE, E_volume, NetE_volume units string Units for returned data (english or metric) metric date string Date (yyyy-mm-dd) 2020-01-01 also_return string Additional metadata attributes to include in response output_format string Response format (json or csv) json"},{"location":"endpoints/timeseries-endpoints/#response_1","title":"Response","text":"<p>Returns a list of dictionaries containing timeseries data for all reservoirs for the specified datasets, variables, and date.</p>"},{"location":"endpoints/timeseries-endpoints/#station-timeseries-data-date-range","title":"Station Timeseries Data (Date Range)","text":"<p>Retrieves timeseries data for one or more stations over a specified date range.</p> <pre><code>import requests\n\nurl = \"https://operevap.dri.edu/timeseries/stations/daterange\"\nheaders = {\n    \"api-key\": \"YOUR_API_KEY\"\n}\nparams = {\n    \"STA_NAMES\": \"LAKE MEAD_STATION\",\n    \"variables\": \"ATemp,RH\",\n    \"start_date\": \"2020-01-01\",\n    \"end_date\": \"2020-01-31\",\n    \"units\": \"metric\",\n    \"output_format\": \"json\"\n}\n\nresponse = requests.get(url, headers=headers, params=params)\ndata = response.json()\nprint(data)\n</code></pre>"},{"location":"endpoints/timeseries-endpoints/#parameters_2","title":"Parameters","text":"Parameter Type Description Default STA_NAMES string One or more station names (comma-separated) LAKE MEAD_STATION, BLW_STATION variables string One or more variables (comma-separated) ATemp, ATemp_Min, ATemp_Max, BP, BR, Ce, DO, DO_percent, EnergyT, ETo, ETr, evap_1, evap_2, evap_3, evap_4, evap_5, HSEnergyFlux, IncomingSR, inflow, SurfaceT, MO_StabilityL, NC_EnergyStored, NR, NW_AdvectedE, outflow, PH, RH, SamplingD, SkinTemp, SpecConduct, SWin, VP, VPD, WTemp, WVD, WD, WS, PofDays units string Units for returned data (english or metric) metric start_date string Start date (yyyy-mm-dd) 2020-01-01 end_date string End date (yyyy-mm-dd) 2020-01-31 also_return string Additional metadata attributes to include in response output_format string Response format (json or csv) json"},{"location":"endpoints/timeseries-endpoints/#response_2","title":"Response","text":"<p>Returns a list of dictionaries containing timeseries data for the specified stations, variables, and date range.</p>"},{"location":"endpoints/timeseries-endpoints/#notes_1","title":"Notes","text":"<ul> <li>Use the <code>/info/list_STA_NAMES</code> endpoint to discover available station names.</li> <li>Use the <code>/info/list_stations_variables</code> endpoint to discover available variables for stations.</li> <li>Use the <code>/info/list_stations_dates</code> endpoint to discover the valid date range for stations.</li> </ul>"},{"location":"endpoints/timeseries-endpoints/#station-timeseries-data-single-date","title":"Station Timeseries Data (Single Date)","text":"<p>Retrieves timeseries data for all stations on a single date.</p> <pre><code>import requests\n\nurl = \"https://operevap.dri.edu/timeseries/stations/date\"\nheaders = {\n    \"api-key\": \"YOUR_API_KEY\"\n}\nparams = {\n    \"variables\": \"ATemp,RH\",\n    \"date\": \"2020-01-01\",\n    \"units\": \"metric\",\n    \"output_format\": \"json\"\n}\n\nresponse = requests.get(url, headers=headers, params=params)\ndata = response.json()\nprint(data)\n</code></pre>"},{"location":"endpoints/timeseries-endpoints/#parameters_3","title":"Parameters","text":"Parameter Type Description Default variables string One or more variables (comma-separated) ATemp, ATemp_Min, ATemp_Max, BP, BR, Ce, DO, DO_percent, EnergyT, ETo, ETr, evap_1, evap_2, evap_3, evap_4, evap_5, HSEnergyFlux, IncomingSR, inflow, SurfaceT, MO_StabilityL, NC_EnergyStored, NR, NW_AdvectedE, outflow, PH, RH, SamplingD, SkinTemp, SpecConduct, SWin, VP, VPD, WTemp, WVD, WD, WS, PofDays units string Units for returned data (english or metric) metric date string Date (yyyy-mm-dd) 2020-01-01 also_return string Additional metadata attributes to include in response output_format string Response format (json or csv) json"},{"location":"endpoints/timeseries-endpoints/#response_3","title":"Response","text":"<p>Returns a list of dictionaries containing timeseries data for all stations for the specified variables and date.</p>"},{"location":"preface/intro/","title":"Reservoir Evaporation API Documentation","text":""},{"location":"preface/intro/#overview","title":"Overview","text":"<p>The Reservoir Evaporation API provides public access to historical and near-real-time daily evaporation estimates from Bureau of Reclamation reservoirs located across 17 western states.</p> <p>This API delivers high-quality data records of evaporation rates and volumes for major reservoirs. The evaporation estimates incorporate meteorological forcing data and reservoir storage information to provide the best available estimates of reservoir evaporation.</p>"},{"location":"preface/intro/#about-this-project","title":"About This Project","text":"<p>Open-water evaporation represents a complex physical process that influences both the water and energy budgets of a lake or reservoir. Though open-water evaporation is critical for water quality, water distribution, and legal accounting, developing reliable estimates is challenging.</p> <p>Historically, water management agencies such as the Bureau of Reclamation (Reclamation) have relied on evaporation estimates from Class A pans for water budget and accounting purposes. While simple and relatively inexpensive to maintain, Class A pans and the associated evaporation estimates have known biases relative to more advanced estimation techniques. This bias, which can depend on water body characteristics like depth and volume, is often attributed to a lack of heat storage in Class A pans relative to real water bodies.</p> <p>This project developed a daily reservoir evaporation database which can be freely accessed and visualized by water managers and stakeholders. This database contains historical and near real-time, high quality data records of evaporation rates and volumes for major reservoirs.</p>"},{"location":"preface/intro/#collaborative-development","title":"Collaborative Development","text":"<p>This API was collaboratively developed by the Bureau of Reclamation (BOR) and Desert Research Institute.</p>"},{"location":"preface/intro/#disclaimer","title":"Disclaimer","text":"<p>Data and information provided through this application are part of an active research project and should be considered provisional and subject to change. Users should perform thorough review prior to operational application and decision making.</p>"},{"location":"preface/intro/#additional-resources","title":"Additional Resources","text":"<ul> <li>Abatzoglou, J. T. (2013), Development of gridded surface meteorological data for ecological applications and modelling. Int. J. Climatol., 33: 121\u2013131.</li> <li>De Pondeca, M. S. F. V., and Coauthors, 2011: The Real-Time Mesoscale Analysis at NOAA's National Centers for Environmental Prediction: Current status and development. Wea. Forecasting, 26, 593\u2013612, https://doi.org/10.1175/WAF-D-10-05037.1.</li> <li>Tanny, J., and Coauthors, 2008: Evaporation from a small water reservoir: Direct measurements and estimates. J. Hydrology, 351, 218-229.</li> <li>Zhao, G., and H. Gao, 2019: Estimating reservoir evaporation losses for the united states: Fusing remote sensing and modeling approaches. Remote Sensing of Environment, 226, 109\u2013124.</li> <li>Zhao, B., and Coauthors, 2023: Developing a Daily Lake Evaporation Model and Generating a Long-term Daily Reservoir Evaporation Dataset in Texas. Submitted to Water Resources Research.</li> </ul>"},{"location":"started/api-playground/","title":"Reservoir Evaporation API Playground","text":""},{"location":"started/authentication/","title":"Authentication","text":""},{"location":"started/authentication/#api-key","title":"API Key","text":"<p>Access to the Reservoir Evaporation API requires an API key. This key must be included with each request to authenticate your application.</p>"},{"location":"started/authentication/#requesting-an-api-key","title":"Requesting an API Key","text":"<p>To obtain an API key, use the following endpoint with Python requests:</p> <pre><code>import requests\n\nurl = \"https://operevap.dri.edu/auth/request_key\"\nparams = {\n    \"name\": \"John Doe\",\n    \"email\": \"john.doe@example.com\",\n    \"justification\": \"Research on reservoir evaporation for climate impact study\"\n}\n\nresponse = requests.get(url, params=params)\nprint(response.text)\n</code></pre>"},{"location":"started/authentication/#parameters","title":"Parameters","text":"Parameter Type Description name string Your full name (First Last) email string A valid email address where the API key will be sent justification string A brief explanation of why you would like an API key and how you will use it"},{"location":"started/authentication/#response","title":"Response","text":"<p>After submitting your request, you should receive an email with your API key within 24 hours.</p>"},{"location":"started/authentication/#using-your-api-key","title":"Using Your API Key","text":"<p>Once you have received your API key, you must include it in the header of each API request:</p> <pre><code>import requests\n\nurl = \"https://operevap.dri.edu/info/list_datasets\"\nheaders = {\n    \"api-key\": \"YOUR_API_KEY\"\n}\n\nresponse = requests.get(url, headers=headers)\ndata = response.json()\nprint(data)\n</code></pre>"},{"location":"started/authentication/#example-getting-csv-output","title":"Example: Getting CSV Output","text":"<pre><code>import requests\n\nurl = \"https://operevap.dri.edu/info/list_datasets\"\nheaders = {\n    \"api-key\": \"YOUR_API_KEY\"\n}\nparams = {\n    \"output_format\": \"csv\"\n}\n\nresponse = requests.get(url, headers=headers, params=params)\ncsv_data = response.text\nprint(csv_data)\n\n# Optionally save to file\nwith open('datasets.csv', 'w') as f:\n    f.write(csv_data)\n</code></pre>"},{"location":"started/authentication/#api-key-security","title":"API Key Security","text":"<ul> <li>Keep your API key secure and do not share it publicly.</li> <li>If you believe your API key has been compromised, request a new one.</li> <li>Do not embed your API key directly in client-side code that is accessible to users.</li> </ul>"},{"location":"started/getting-started/","title":"Getting Started","text":"<p>This section provides an overview of how to begin using the Reservoir Evaporation API.</p>"},{"location":"started/getting-started/#prerequisites","title":"Prerequisites","text":"<p>Before using the API, you will need:</p> <ol> <li>An API key (see Authentication)</li> <li>Basic understanding of REST APIs and HTTP requests</li> <li>A tool to make HTTP requests (e.g., cURL, Postman, or programming languages like Python, JavaScript, etc.)</li> </ol>"},{"location":"started/getting-started/#base-url","title":"Base URL","text":"<p>All API requests should be made to the base URL of the API:</p> <pre><code>https://operevap.dri.edu\n</code></pre>"},{"location":"started/getting-started/#request-format","title":"Request Format","text":"<p>The API accepts request parameters as query parameters in the URL. Here's an example using Python requests:</p> <pre><code>import requests\n\nparams = {\n    \"RES_NAMES\": \"LAKE ALICE\",\n    \"start_date\": \"2020-01-01\",\n    \"end_date\": \"2020-01-31\"\n}\n\nurl = \"https://operevap.dri.edu/timeseries/daily/reservoirs/daterange\"\nheaders = {\n    \"api-key\": \"YOUR_API_KEY\"\n}\n\nresponse = requests.get(url, params=params, headers=headers)\ndata = response.json()\nprint(data)\n</code></pre>"},{"location":"started/getting-started/#response-format","title":"Response Format","text":"<p>The API returns data in either JSON or CSV format, which can be specified using the <code>output_format</code> parameter in your requests:</p> <ul> <li><code>output_format=json</code> (default)</li> <li><code>output_format=csv</code></li> </ul> <p>Example of requesting CSV output:</p> <pre><code>import requests\n\nparams = {\n    \"RES_NAMES\": \"LAKE ALICE\",\n    \"start_date\": \"2020-01-01\",\n    \"end_date\": \"2020-01-31\",\n    \"output_format\": \"csv\"\n}\n\nurl = \"https://operevap.dri.edu/timeseries/daily/reservoirs/daterange\"\nheaders = {\n    \"api-key\": \"YOUR_API_KEY\"\n}\n\nresponse = requests.get(url, params=params, headers=headers)\ncsv_data = response.text\nprint(csv_data)\n\n# Optionally save to file\nwith open('lake_alice_data.csv', 'w') as f:\n    f.write(csv_data)\n</code></pre>"},{"location":"started/getting-started/#units","title":"Units","text":"<p>For endpoints that return numerical values, you can specify whether you want the data in metric or English units using the <code>units</code> parameter:</p> <ul> <li><code>units=metric</code> (default)</li> <li><code>units=english</code></li> </ul> <p>Example using English units:</p> <pre><code>import requests\n\nparams = {\n    \"RES_NAMES\": \"LAKE ALICE\",\n    \"start_date\": \"2020-01-01\",\n    \"end_date\": \"2020-01-31\",\n    \"units\": \"english\"\n}\n\nurl = \"https://operevap.dri.edu/timeseries/daily/reservoirs/daterange\"\nheaders = {\n    \"api-key\": \"YOUR_API_KEY\"\n}\n\nresponse = requests.get(url, params=params, headers=headers)\ndata = response.json()\nprint(data)\n</code></pre>"},{"location":"started/getting-started/#api-sections","title":"API Sections","text":"<p>The API is organized into the following sections:</p> <ol> <li>Auth - Endpoints for requesting API keys</li> <li>Help/Info - Endpoints for discovering available datasets, variables, reservoirs, stations, and date ranges</li> <li>Metadata - Endpoints for retrieving metadata about reservoirs and stations</li> <li>Timeseries - Endpoints for retrieving timeseries data for reservoirs and stations</li> </ol>"},{"location":"started/getting-started/#python-example","title":"Python Example","text":"<p>A Python example for interacting with the API is available at: https://drive.google.com/drive/folders/1_JAM9JGwf40Tjo3fkx28mIP1tW5M55AO?usp=sharing</p> <p>This example can help you get started with using the API in your Python applications.</p>"},{"location":"started/getting-started/#next-steps","title":"Next Steps","text":"<ol> <li>Request an API key</li> <li>Explore the available reservoirs and stations</li> <li>Retrieve metadata for your reservoirs of interest</li> <li>Retrieve timeseries data for your analysis</li> </ol>"}]}