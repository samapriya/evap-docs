{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Reservoir Evaporation API Documentation","text":""},{"location":"#overview","title":"Overview","text":"<p>The Reservoir Evaporation API provides public access to historical and near-real-time daily evaporation estimates from Bureau of Reclamation reservoirs located across 17 western states.</p> <p>This API delivers high-quality data records of evaporation rates and volumes for major reservoirs. The evaporation estimates incorporate meteorological forcing data and reservoir storage information to provide the best available estimates of reservoir evaporation.</p>"},{"location":"#about-this-project","title":"About This Project","text":"<p>Open-water evaporation represents a complex physical process that influences both the water and energy budgets of a lake or reservoir. Though open-water evaporation is critical for water quality, water distribution, and legal accounting, developing reliable estimates is challenging.</p> <p>Historically, water management agencies such as the Bureau of Reclamation (Reclamation) have relied on evaporation estimates from Class A pans for water budget and accounting purposes. While simple and relatively inexpensive to maintain, Class A pans and the associated evaporation estimates have known biases relative to more advanced estimation techniques. This bias, which can depend on water body characteristics like depth and volume, is often attributed to a lack of heat storage in Class A pans relative to real water bodies.</p> <p>This project developed a daily reservoir evaporation database which can be freely accessed and visualized by water managers and stakeholders. This database contains historical and near real-time, high quality data records of evaporation rates and volumes for major reservoirs.</p>"},{"location":"#collaborative-development","title":"Collaborative Development","text":"<p>This API was collaboratively developed by the Bureau of Reclamation (BOR) and Desert Research Institute.</p>"},{"location":"#disclaimer","title":"Disclaimer","text":"<p>Data and information provided through this application are part of an active research project and should be considered provisional and subject to change. Users should perform thorough review prior to operational application and decision making.</p>"},{"location":"#additional-resources","title":"Additional Resources","text":"<ul> <li>Abatzoglou, J. T. (2013), Development of gridded surface meteorological data for ecological applications and modelling. Int. J. Climatol., 33: 121\u2013131.</li> <li>De Pondeca, M. S. F. V., and Coauthors, 2011: The Real-Time Mesoscale Analysis at NOAA's National Centers for Environmental Prediction: Current status and development. Wea. Forecasting, 26, 593\u2013612, https://doi.org/10.1175/WAF-D-10-05037.1.</li> <li>Tanny, J., and Coauthors, 2008: Evaporation from a small water reservoir: Direct measurements and estimates. J. Hydrology, 351, 218-229.</li> <li>Zhao, G., and H. Gao, 2019: Estimating reservoir evaporation losses for the united states: Fusing remote sensing and modeling approaches. Remote Sensing of Environment, 226, 109\u2013124.</li> <li>Zhao, B., and Coauthors, 2023: Developing a Daily Lake Evaporation Model and Generating a Long-term Daily Reservoir Evaporation Dataset in Texas. Submitted to Water Resources Research.</li> </ul>"},{"location":"appendix/","title":"Appendix","text":""},{"location":"appendix/#available-variables","title":"Available Variables","text":""},{"location":"appendix/#reservoir-variables","title":"Reservoir Variables","text":"<p>The following variables are available for reservoirs across different datasets:</p>"},{"location":"appendix/#rtma-dataset-weather-variables","title":"RTMA Dataset (Weather Variables)","text":"Variable Description Units (Metric) Units (English) pr Precipitation mm in tmmx_c Maximum temperature \u00b0C \u00b0F tmmn_c Minimum temperature \u00b0C \u00b0F vpd_kpa Vapor pressure deficit kPa kPa vs2m Wind speed at 2 meters m/s mph srad Solar radiation W/m\u00b2 W/m\u00b2 th Specific humidity kg/kg kg/kg sph_kgkg Specific humidity kg/kg kg/kg pres_pa Air pressure Pa Pa"},{"location":"appendix/#res-dataset-reservoir-physical-variables","title":"RES Dataset (Reservoir Physical Variables)","text":"Variable Description Units (Metric) Units (English) stage_m Water surface elevation m ft area_m2 Surface area m\u00b2 acre depth_m Average depth m ft"},{"location":"appendix/#lem-dataset-energy-balance-variables","title":"LEM Dataset (Energy Balance Variables)","text":"Variable Description Units (Metric) Units (English) E_hs Heat storage evaporation mm/day in/day E_nhs No heat storage evaporation mm/day in/day Rn Net radiation W/m\u00b2 W/m\u00b2 Tw Water temperature \u00b0C \u00b0F Tw0 Surface water temperature \u00b0C \u00b0F Fetch Fetch m ft Lerr Latent heat of evaporation W/m\u00b2 W/m\u00b2"},{"location":"appendix/#nete-volume-calcs-dataset-evaporation-variables","title":"NETE-VOLUME-CALCS Dataset (Evaporation Variables)","text":"Variable Description Units (Metric) Units (English) NetE Net evaporation mm/day in/day E_volume Evaporation volume m\u00b3 acre-ft NetE_volume Net evaporation volume m\u00b3 acre-ft"},{"location":"appendix/#station-variables","title":"Station Variables","text":"<p>The following variables are available for stations:</p> Variable Description Units (Metric) Units (English) ATemp Air temperature \u00b0C \u00b0F ATemp_Min Minimum air temperature \u00b0C \u00b0F ATemp_Max Maximum air temperature \u00b0C \u00b0F BP Barometric pressure hPa inHg BR Bowen ratio unitless unitless Ce Bulk transfer coefficient unitless unitless DO Dissolved oxygen mg/L mg/L DO_percent Dissolved oxygen percentage % % EnergyT Energy balance term W/m\u00b2 W/m\u00b2 ETo Reference evapotranspiration (grass) mm/day in/day ETr Reference evapotranspiration (alfalfa) mm/day in/day evap_1 Evaporation method 1 mm/day in/day evap_2 Evaporation method 2 mm/day in/day evap_3 Evaporation method 3 mm/day in/day evap_4 Evaporation method 4 mm/day in/day evap_5 Evaporation method 5 mm/day in/day HSEnergyFlux Heat storage energy flux W/m\u00b2 W/m\u00b2 IncomingSR Incoming solar radiation W/m\u00b2 W/m\u00b2 inflow Inflow m\u00b3/s cfs SurfaceT Surface temperature \u00b0C \u00b0F MO_StabilityL Monin-Obukhov stability length m ft NC_EnergyStored Net change in energy stored W/m\u00b2 W/m\u00b2 NR Net radiation W/m\u00b2 W/m\u00b2 NW_AdvectedE Net advected energy W/m\u00b2 W/m\u00b2 outflow Outflow m\u00b3/s cfs PH pH unitless unitless RH Relative humidity % % SamplingD Sampling depth m ft SkinTemp Skin temperature \u00b0C \u00b0F SpecConduct Specific conductance \u03bcS/cm \u03bcS/cm SWin Incoming shortwave radiation W/m\u00b2 W/m\u00b2 VP Vapor pressure kPa kPa VPD Vapor pressure deficit kPa kPa WTemp Water temperature \u00b0C \u00b0F WVD Wind vector direction degrees degrees WD Wind direction degrees degrees WS Wind speed m/s mph PofDays Percentage of days with data % %"},{"location":"appendix/#http-status-codes","title":"HTTP Status Codes","text":"<p>The API may return the following HTTP status codes:</p> Status Code Description 200 Successful response 401 Unauthorized (invalid or missing API key) 404 Not found (resource not found) 422 Validation error (invalid parameters) 500 Server error"},{"location":"appendix/#data-quality-flags","title":"Data Quality Flags","text":"<p>The API may include quality flags in the response data. These flags indicate the quality or reliability of the data:</p> Flag Description 0 Good data 1 Suspect data (automatically flagged) 2 Suspect data (manually flagged) 3 Missing data (gap filled) 9 Missing data (not filled)"},{"location":"appendix/#file-formats","title":"File Formats","text":""},{"location":"appendix/#shapefile-components","title":"Shapefile Components","text":"<p>When uploading shapefiles to filter reservoirs or stations by location, the following files are required:</p> File Extension Description .shp The main file that stores the geometry .dbf The database file that stores the attributes .prj The projection file that stores the coordinate system .shx The index file that stores the index of the geometry"},{"location":"appendix/#glossary","title":"Glossary","text":"Term Definition Evaporation The process by which water changes from a liquid to a gas or vapor Net Evaporation The difference between evaporation and precipitation (evaporation minus precipitation) Reservoir A large natural or artificial lake used as a source of water supply Timeseries A series of data points indexed in time order Metadata Data that provides information about other data API Application Programming Interface REST Representational State Transfer, an architectural style for APIs JSON JavaScript Object Notation, a lightweight data-interchange format CSV Comma-Separated Values, a text file format that uses commas to separate values Dataset A collection of data Variable A measurable property Units The standard of measurement Metric The International System of Units (SI) English The US Customary Units Quality Flag An indicator of the quality or reliability of the data Shapefile A geospatial vector data format for geographic information system software"},{"location":"changelog/","title":"Changelog","text":""},{"location":"examples/","title":"Examples","text":"<p>This section provides example code snippets for common tasks using the Reservoir Evaporation API. NOTE: R and cURL have not been tested yet!</p>"},{"location":"examples/#setup","title":"Setup","text":""},{"location":"examples/#set-up-a-virtual-environment","title":"Set up a virtual environment","text":"<pre><code>```bash\npython3 -m venv venv\nsource venv/bin/activate\npip install geopandas\npip install matplotlib\npip install pandas\npip install requests\n```\n</code></pre> PythonRcURL <pre><code>import requests\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport json\n\n# API configuration\nAPI_KEY = \"your_api_key_here\"\nBASE_URL = \"https://operevap.dri.edu/\"  # Replace with the actual API base URL\nHEADERS = {\n    \"api-key\": API_KEY\n}\n</code></pre> <pre><code>library(httr)\nlibrary(jsonlite)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(lubridate)\n\n# API configuration\nAPI_KEY &lt;- \"your_api_key_here\"\nBASE_URL &lt;- \"https://api-url.example\"  # Replace with the actual API base URL\nHEADERS &lt;- add_headers(`api-key` = API_KEY)\n</code></pre> <pre><code># Store your API key and base URL for reuse\nAPI_KEY=\"your_api_key_here\"\nBASE_URL=\"https://api-url.example\"  # Replace with the actual API base URL\n</code></pre>"},{"location":"examples/#get-available-reservoirs","title":"Get Available Reservoirs","text":"PythonRcURL <pre><code>def get_reservoirs():\n    \"\"\"Get a list of available reservoirs.\"\"\"\n    url = f\"{BASE_URL}/info/list_RES_NAMES\"\n    response = requests.post(url, headers=HEADERS)\n\n    if response.status_code == 200 and \"RES_NAMES\" in response.json().keys():\n        return response.json()[\"RES_NAMES]\n    else:\n        print(f\"Error: {response.status_code}\")\n        return None\n\n# Example usage\nreservoirs = get_reservoirs()\nif reservoirs:\n    print(f\"Number of reservoirs: {len(reservoirs)}\")\n    print(\"First 5 reservoirs:\")\n    for res in reservoirs[:5]:\n        print(f\"- {res}\")\n</code></pre> <pre><code>get_reservoirs &lt;- function() {\n  # Get a list of available reservoirs\n  url &lt;- paste0(BASE_URL, \"/info/list_RES_NAMES\")\n  response &lt;- GET(url, HEADERS)\n\n  if (status_code(response) == 200) {\n    return(fromJSON(content(response, \"text\", encoding = \"UTF-8\")))\n  } else {\n    print(paste(\"Error:\", status_code(response)))\n    return(NULL)\n  }\n}\n\n# Example usage\nreservoirs &lt;- get_reservoirs()\nprint(paste(\"Number of reservoirs:\", length(reservoirs)))\nprint(\"First 5 reservoirs:\")\nfor (i in 1:5) {\n  print(paste(\"-\", reservoirs[i]))\n}\n</code></pre> <pre><code># Get a list of available reservoirs\ncurl -X POST \"${BASE_URL}/info/list_RES_NAMES\" \\\n     -H \"api-key: ${API_KEY}\" \\\n     -H \"Content-Type: application/json\"\n</code></pre>"},{"location":"examples/#get-reservoir-metadata","title":"Get Reservoir Metadata","text":"PythonRcURL <pre><code>def get_reservoir_metadata(reservoir_names):\n    \"\"\"Get metadata for specified reservoirs.\"\"\"\n    url = f\"{BASE_URL}/metadata/reservoirs\"\n    params = {\n        \"RES_NAMES\": \",\".join(reservoir_names),\n        \"output_format\": \"json\"\n    }\n\n    response = requests.get(url, headers=HEADERS, params=params)\n\n    if response.status_code == 200:\n        return response.json()\n    else:\n        print(f\"Error: {response.status_code}\")\n        return None\n\n# Example usage\nreservoir_metadata = get_reservoir_metadata([\"LAKE ALICE\", \"LAKE ESTES\"])\nfor res in reservoir_metadata:\n    print(f\"Reservoir: {res['RES_NAME']}\")\n    print(f\"  Latitude: {res['LAT']}\")\n    print(f\"  Longitude: {res['LON']}\")\n    print(f\"  State: {res['Shape_Area']}\")\n</code></pre> <pre><code>get_reservoir_metadata &lt;- function(reservoir_names) {\n  # Get metadata for specified reservoirs\n  url &lt;- paste0(BASE_URL, \"/metadata/reservoirs\")\n  params &lt;- list(\n    RES_NAMES = paste(reservoir_names, collapse = \",\"),\n    output_format = \"json\"\n  )\n\n  response &lt;- GET(url, HEADERS, query = params)\n\n  if (status_code(response) == 200) {\n    return(fromJSON(content(response, \"text\", encoding = \"UTF-8\")))\n  } else {\n    print(paste(\"Error:\", status_code(response)))\n    return(NULL)\n  }\n}\n\n# Example usage\nreservoir_metadata &lt;- get_reservoir_metadata(c(\"LAKE ALICE\", \"LAKE ESTES\"))\nfor (i in 1:length(reservoir_metadata$res_name)) {\n  print(paste(\"Reservoir:\", reservoir_metadata$res_name[i]))\n  print(paste(\"  Latitude:\", reservoir_metadata$latitude[i]))\n  print(paste(\"  Longitude:\", reservoir_metadata$longitude[i]))\n  print(paste(\"  State:\", reservoir_metadata$state[i]))\n}\n</code></pre> <pre><code># Get metadata for specified reservoirs\ncurl -X GET \"${BASE_URL}/metadata/reservoirs?RES_NAMES=LAKE%20ALICE,LAKE%20ESTES&amp;output_format=json\" \\\n     -H \"api-key: ${API_KEY}\"\n</code></pre>"},{"location":"examples/#get-timeseries-data-for-a-reservoir","title":"Get Timeseries Data for a Reservoir","text":"PythonRcURL <pre><code>def get_reservoir_timeseries(reservoir_name, start_date, end_date):\n    \"\"\"Get timeseries data for a reservoir.\"\"\"\n    url = f\"{BASE_URL}/timeseries/daily/reservoirs/daterange\"\n    params = {\n        \"RES_NAMES\": reservoir_name,\n        \"datasets\": \"nete-volume-calcs\",\n        \"variables\": \"NetE,E_volume\",\n        \"start_date\": start_date,\n        \"end_date\": end_date,\n        \"units\": \"metric\",\n        \"output_format\": \"json\"\n    }\n\n    response = requests.get(url, headers=HEADERS, params=params)\n\n    if response.status_code == 200:\n        return response.json()\n    else:\n        print(f\"Error: {response.status_code}\")\n        return None\n\n# Example usage\ndata = get_reservoir_timeseries(\"LAKE ALICE\", \"2020-01-01\", \"2020-12-31\")\n\n# Convert to pandas DataFrame for analysis\ndf = pd.DataFrame(data)\ndf['start_date'] = pd.to_datetime(df['start_date'])\ndf.set_index('start_date', inplace=True)\n\n# Plot the data\nplt.figure(figsize=(12, 6))\nplt.plot(df.index, df['NetE (mm)'], label='Net Evaporation')\nplt.title('Net Evaporation for LAKE ALICE (2020)')\nplt.xlabel('Date')\nplt.ylabel('Net Evaporation (mm/day)')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n</code></pre> <pre><code>get_reservoir_timeseries &lt;- function(reservoir_name, start_date, end_date) {\n  # Get timeseries data for a reservoir\n  url &lt;- paste0(BASE_URL, \"/timeseries/daily/reservoirs/daterange\")\n  params &lt;- list(\n    RES_NAMES = reservoir_name,\n    datasets = \"nete-volume-calcs\",\n    variables = \"NetE,E_volume\",\n    start_date = start_date,\n    end_date = end_date,\n    units = \"metric\",\n    output_format = \"json\"\n  )\n\n  response &lt;- GET(url, HEADERS, query = params)\n\n  if (status_code(response) == 200) {\n    return(fromJSON(content(response, \"text\", encoding = \"UTF-8\")))\n  } else {\n    print(paste(\"Error:\", status_code(response)))\n    return(NULL)\n  }\n}\n\n# Example usage\ndata &lt;- get_reservoir_timeseries(\"LAKE ALICE\", \"2020-01-01\", \"2020-12-31\")\n\n# Convert to data frame for analysis\ndf &lt;- as.data.frame(data)\ndf$start_date &lt;- as.Date(df$start_date)\n\n# Plot the data\nggplot(df, aes(x = start_date, y = NetE (mm))) +\n  geom_line() +\n  labs(\n    title = \"Net Evaporation for LAKE ALICE (2020)\",\n    x = \"Date\",\n    y = \"Net Evaporation (mm/day)\"\n  ) +\n  theme_minimal() +\n  theme(\n    panel.grid = element_line(color = \"gray90\"),\n    plot.title = element_text(hjust = 0.5)\n  )\n</code></pre> <pre><code># Get timeseries data for a reservoir\ncurl -X GET \"${BASE_URL}/timeseries/daily/reservoirs/daterange?RES_NAMES=LAKE%20ALICE&amp;datasets=nete-volume-calcs&amp;variables=NetE,E_volume&amp;start_date=2020-01-01&amp;end_date=2020-12-31&amp;units=metric&amp;output_format=json\" \\\n     -H \"api-key: ${API_KEY}\"\n</code></pre>"},{"location":"examples/#compare-evaporation-between-multiple-reservoirs","title":"Compare Evaporation Between Multiple Reservoirs","text":"PythonRcURL <pre><code>def compare_reservoirs(reservoir_names, start_date, end_date, variable=\"NetE\"):\n    \"\"\"Compare a variable between multiple reservoirs.\"\"\"\n    url = f\"{BASE_URL}/timeseries/daily/reservoirs/daterange\"\n    params = {\n        \"RES_NAMES\": \",\".join(reservoir_names),\n        \"datasets\": \"nete-volume-calcs\",\n        \"variables\": variable,\n        \"start_date\": start_date,\n        \"end_date\": end_date,\n        \"units\": \"metric\",\n        \"output_format\": \"json\"\n    }\n\n    response = requests.get(url, headers=HEADERS, params=params)\n\n    if response.status_code == 200:\n        return response.json()\n    else:\n        print(f\"Error: {response.status_code}\")\n        return None\n\n# Example usage\nreservoirs_to_compare = [\"LAKE ALICE\", \"LAKE ESTES\", \"RUEDI RESERVOIR\"]\ncomparison_data = compare_reservoirs(reservoirs_to_compare, \"2020-06-01\", \"2020-08-31\")\n\n# Process and visualize data\ndf = pd.DataFrame(comparison_data)\ndf['start_date'] = pd.to_datetime(df['start_date'])\n\n# Pivot the data to have one column per reservoir\npivot_df = df.pivot_table(index='start_date', columns='RES_NAME', values='NetE (mm)')\n\n# Plot the data\nplt.figure(figsize=(12, 6))\nfor reservoir in reservoirs_to_compare:\n    plt.plot(pivot_df.index, pivot_df[reservoir], label=reservoir)\n\nplt.title('Net Evaporation Comparison (Summer 2020)')\nplt.xlabel('Date')\nplt.ylabel('Net Evaporation (mm/day)')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n</code></pre> <pre><code>compare_reservoirs &lt;- function(reservoir_names, start_date, end_date, variable = \"NetE (mm)\") {\n  # Compare a variable between multiple reservoirs\n  url &lt;- paste0(BASE_URL, \"/timeseries/daily/reservoirs/daterange\")\n  params &lt;- list(\n    RES_NAMES = paste(reservoir_names, collapse = \",\"),\n    datasets = \"nete-volume-calcs\",\n    variables = variable,\n    start_date = start_date,\n    end_date = end_date,\n    units = \"metric\",\n    output_format = \"json\"\n  )\n\n  response &lt;- GET(url, HEADERS, query = params)\n\n  if (status_code(response) == 200) {\n    return(fromJSON(content(response, \"text\", encoding = \"UTF-8\")))\n  } else {\n    print(paste(\"Error:\", status_code(response)))\n    return(NULL)\n  }\n}\n\n# Example usage\nreservoirs_to_compare &lt;- c(\"LAKE ALICE\", \"LAKE ESTES\", \"RUEDI RESERVOIR\")\ncomparison_data &lt;- compare_reservoirs(reservoirs_to_compare, \"2020-06-01\", \"2020-08-31\")\n\n# Process and visualize data\ndf &lt;- as.data.frame(comparison_data)\ndf$start_date &lt;- as.Date(df$start_date)\n\n# Prepare data for plotting\ndf_wide &lt;- df %&gt;%\n  pivot_wider(\n    id_cols = start_date,\n    names_from = RES_NAME,\n    values_from = NetE (mm)\n  )\n\n# Reshape for ggplot\ndf_long &lt;- df %&gt;%\n  select(start_date, RES_NAME, NetE (mm))\n\n# Plot the data\nggplot(df_long, aes(x = start_date, y = NetE (mm), color = RES_NAME)) +\n  geom_line() +\n  labs(\n    title = \"Net Evaporation Comparison (Summer 2020)\",\n    x = \"Date\",\n    y = \"Net Evaporation (mm/day)\",\n    color = \"Reservoir\"\n  ) +\n  theme_minimal() +\n  theme(\n    panel.grid = element_line(color = \"gray90\"),\n    plot.title = element_text(hjust = 0.5),\n    legend.position = \"bottom\"\n  )\n</code></pre> <pre><code># Compare evaporation between multiple reservoirs\ncurl -X GET \"${BASE_URL}/timeseries/daily/reservoirs/daterange?RES_NAMES=LAKE%20ALICE,LAKE%20ESTES,RUEDI%20RESERVOIR&amp;datasets=nete-volume-calcs&amp;variables=NetE&amp;start_date=2020-06-01&amp;end_date=2020-08-31&amp;units=metric&amp;output_format=json\" \\\n     -H \"api-key: ${API_KEY}\"\n</code></pre>"},{"location":"examples/#calculate-monthly-evaporation-volumes","title":"Calculate Monthly Evaporation Volumes","text":"PythonRcURL <pre><code>def get_monthly_evaporation_volumes(reservoir_name, year):\n    \"\"\"Calculate monthly evaporation volumes for a reservoir.\"\"\"\n    start_date = f\"{year}-01-01\"\n    end_date = f\"{year}-12-31\"\n\n    url = f\"{BASE_URL}/timeseries/daily/reservoirs/daterange\"\n    params = {\n        \"RES_NAMES\": reservoir_name,\n        \"datasets\": \"nete-volume-calcs\",\n        \"variables\": \"E_volume\",\n        \"start_date\": start_date,\n        \"end_date\": end_date,\n        \"units\": \"metric\",\n        \"output_format\": \"json\"\n    }\n\n    response = requests.get(url, headers=HEADERS, params=params)\n\n    if response.status_code == 200:\n        data = response.json()\n        df = pd.DataFrame(data)\n        df['start_date'] = pd.to_datetime(df['start_date'])\n        df.set_index('start_date', inplace=True)\n\n        # Calculate monthly totals\n        monthly_data = df.resample('M').sum()\n        monthly_data.index = monthly_data.index.strftime('%b')\n\n        return monthly_data\n    else:\n        print(f\"Error: {response.status_code}\")\n        return None\n\n# Example usage\nmonthly_volumes = get_monthly_evaporation_volumes(\"LAKE MEAD\", 2020)\n\n# Plot monthly volumes\nplt.figure(figsize=(12, 6))\nplt.bar(monthly_volumes.index, monthly_volumes['E_volume (m3)'])\nplt.title('Monthly Evaporation Volumes for LAKE MEAD (2020)')\nplt.xlabel('Month')\nplt.ylabel('Evaporation Volume (cubic meters)')\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n</code></pre> <pre><code>get_monthly_evaporation_volumes &lt;- function(reservoir_name, year) {\n  # Calculate monthly evaporation volumes for a reservoir\n  start_date &lt;- paste0(year, \"-01-01\")\n  end_date &lt;- paste0(year, \"-12-31\")\n\n  url &lt;- paste0(BASE_URL, \"/timeseries/daily/reservoirs/daterange\")\n  params &lt;- list(\n    RES_NAMES = reservoir_name,\n    datasets = \"nete-volume-calcs\",\n    variables = \"E_volume\",\n    start_date = start_date,\n    end_date = end_date,\n    units = \"metric\",\n    output_format = \"json\"\n  )\n\n  response &lt;- GET(url, HEADERS, query = params)\n\n  if (status_code(response) == 200) {\n    data &lt;- fromJSON(content(response, \"text\", encoding = \"UTF-8\"))\n    df &lt;- as.data.frame(data)\n    df$start_date &lt;- as.Date(df$start_date)\n\n    # Calculate monthly totals\n    monthly_data &lt;- df %&gt;%\n      mutate(month = format(start_date, \"%b\")) %&gt;%\n      group_by(month) %&gt;%\n      summarize(E_volume = sum(E_volume (m3), na.rm = TRUE)) %&gt;%\n      mutate(month = factor(month, levels = month.abb))\n\n    return(monthly_data)\n  } else {\n    print(paste(\"Error:\", status_code(response)))\n    return(NULL)\n  }\n}\n\n# Example usage\nmonthly_volumes &lt;- get_monthly_evaporation_volumes(\"LAKE MEAD\", 2020)\n\n# Plot monthly volumes\nggplot(monthly_volumes, aes(x = month, y = E_volume (m3))) +\n  geom_col(fill = \"steelblue\") +\n  labs(\n    title = \"Monthly Evaporation Volumes for LAKE MEAD (2020)\",\n    x = \"Month\",\n    y = \"Evaporation Volume (cubic meters)\"\n  ) +\n  theme_minimal() +\n  theme(\n    panel.grid = element_line(color = \"gray90\"),\n    plot.title = element_text(hjust = 0.5)\n  )\n</code></pre> <pre><code># Get monthly evaporation volumes data\ncurl -X GET \"${BASE_URL}/timeseries/daily/reservoirs/daterange?RES_NAMES=LAKE%20MEAD&amp;datasets=nete-volume-calcs&amp;variables=E_volume&amp;start_date=2020-01-01&amp;end_date=2020-12-31&amp;units=metric&amp;output_format=json\" \\\n     -H \"api-key: ${API_KEY}\"\n</code></pre>"},{"location":"examples/#retrieve-and-analyze-weather-data-for-a-reservoir","title":"Retrieve and Analyze Weather Data for a Reservoir","text":"PythonRcURL <pre><code>def get_weather_data(reservoir_name, start_date, end_date):\n    \"\"\"Get weather data for a reservoir.\"\"\"\n    url = f\"{BASE_URL}/timeseries/daily/reservoirs/daterange\"\n    params = {\n        \"RES_NAMES\": reservoir_name,\n        \"datasets\": \"rtma\",\n        \"variables\": \"pr,tmmx_c,tmmn_c,vpd_kpa,srad\",\n        \"start_date\": start_date,\n        \"end_date\": end_date,\n        \"units\": \"metric\",\n        \"output_format\": \"json\"\n    }\n\n    response = requests.get(url, headers=HEADERS, params=params)\n\n    if response.status_code == 200:\n        return response.json()\n    else:\n        print(f\"Error: {response.status_code}\")\n        return None\n\n# Example usage\nweather_data = get_weather_data(\"LAKE POWELL\", \"2020-06-01\", \"2020-08-31\")\ndf = pd.DataFrame(weather_data)\ndf['start_date'] = pd.to_datetime(df['start_date'])\ndf.set_index('start_date', inplace=True)\n\n# Calculate monthly averages\nmonthly_weather = df.resample('M').agg({\n    'pr (mm)': 'sum',\n    'tmmx_c (degC)': 'mean',\n    'tmmn_c (degC)': 'mean',\n    'vpd_kpa (kpa)': 'mean',\n    'srad (wm2)': 'mean'\n})\n\nprint(\"Monthly Weather Summary for LAKE POWELL (Summer 2020):\")\nprint(f\"Month | Total Precip (mm) | Avg Max Temp (\u00b0C) | Avg Min Temp (\u00b0C)\")\nfor idx, row in monthly_weather.iterrows():\n    month = idx.strftime('%b %Y')\n    print(f\"{month} | {row['pr (mm)']:.1f} | {row['tmmx_c (degC)']:.1f} | {row['tmmn_c (degC)']:.1f}\")\n</code></pre> <pre><code>get_weather_data &lt;- function(reservoir_name, start_date, end_date) {\n  # Get weather data for a reservoir\n  url &lt;- paste0(BASE_URL, \"/timeseries/daily/reservoirs/daterange\")\n  params &lt;- list(\n    RES_NAMES = reservoir_name,\n    datasets = \"rtma\",\n    variables = \"pr,tmmx_c,tmmn_c,vpd_kpa,srad\",\n    start_date = start_date,\n    end_date = end_date,\n    units = \"metric\",\n    output_format = \"json\"\n  )\n\n  response &lt;- GET(url, HEADERS, query = params)\n\n  if (status_code(response) == 200) {\n    return(fromJSON(content(response, \"text\", encoding = \"UTF-8\")))\n  } else {\n    print(paste(\"Error:\", status_code(response)))\n    return(NULL)\n  }\n}\n\n# Example usage\nweather_data &lt;- get_weather_data(\"LAKE POWELL\", \"2020-06-01\", \"2020-08-31\")\ndf &lt;- as.data.frame(weather_data)\ndf$start_date &lt;- as.Date(df$start_date)\n\n# Calculate monthly averages\nmonthly_weather &lt;- df %&gt;%\n  mutate(month = format(start_date, \"%b %Y\")) %&gt;%\n  group_by(month) %&gt;%\n  summarize(\n    pr_total = sum(pr (mm), na.rm = TRUE),\n    tmmx_c_avg = mean(tmmx_c (degC), na.rm = TRUE),\n    tmmn_c_avg = mean(tmmn_c (degC), na.rm = TRUE),\n    vpd_kpa_avg = mean(vpd_kpa (kpa), na.rm = TRUE),\n    srad_avg = mean(srad (wm2), na.rm = TRUE)\n  )\n\n# Print monthly summary\ncat(\"Monthly Weather Summary for LAKE POWELL (Summer 2020):\\n\")\ncat(\"Month | Total Precip (mm) | Avg Max Temp (\u00b0C) | Avg Min Temp (\u00b0C)\\n\")\n\nfor (i in 1:nrow(monthly_weather)) {\n  cat(sprintf(\"%s | %.1f | %.1f | %.1f\\n\",\n             monthly_weather$month[i],\n             monthly_weather$pr_total[i],\n             monthly_weather$tmmx_c_avg[i],\n             monthly_weather$tmmn_c_avg[i]))\n}\n</code></pre> <pre><code># Get weather data for a reservoir\ncurl -X GET \"${BASE_URL}/timeseries/daily/reservoirs/daterange?RES_NAMES=LAKE%20POWELL&amp;datasets=rtma&amp;variables=pr,tmmx_c,tmmn_c,vpd_kpa,srad&amp;start_date=2020-06-01&amp;end_date=2020-08-31&amp;units=metric&amp;output_format=json\" \\\n     -H \"api-key: ${API_KEY}\"\n</code></pre>"},{"location":"examples/#working-with-multiple-datasets","title":"Working with Multiple Datasets","text":""},{"location":"examples/#combine-evaporation-and-weather-data","title":"Combine Evaporation and Weather Data","text":"PythonRcURL <pre><code>def combine_datasets(reservoir_name, start_date, end_date):\n    \"\"\"Combine evaporation and weather data for analysis.\"\"\"\n    # Get evaporation data\n    evap_url = f\"{BASE_URL}/timeseries/daily/reservoirs/daterange\"\n    evap_params = {\n        \"RES_NAMES\": reservoir_name,\n        \"datasets\": \"nete-volume-calcs\",\n        \"variables\": \"NetE,E_volume\",\n        \"start_date\": start_date,\n        \"end_date\": end_date,\n        \"units\": \"metric\",\n        \"output_format\": \"json\"\n    }\n\n    evap_response = requests.get(evap_url, headers=HEADERS, params=evap_params)\n\n    # Get weather data\n    weather_url = f\"{BASE_URL}/timeseries/daily/reservoirs/daterange\"\n    weather_params = {\n        \"RES_NAMES\": reservoir_name,\n        \"datasets\": \"rtma\",\n        \"variables\": \"pr,tmmx_c,tmmn_c,vpd_kpa,srad\",\n        \"start_date\": start_date,\n        \"end_date\": end_date,\n        \"units\": \"metric\",\n        \"output_format\": \"json\"\n    }\n\n    weather_response = requests.get(weather_url, headers=HEADERS, params=weather_params)\n\n    if evap_response.status_code == 200 and weather_response.status_code == 200:\n        evap_data = pd.DataFrame(evap_response.json())\n        weather_data = pd.DataFrame(weather_response.json())\n\n        # Prepare data\n        evap_data['start_date'] = pd.to_datetime(evap_data['start_date'])\n        evap_data.set_index(['start_date', 'RES_NAME'], inplace=True)\n\n        weather_data['date'] = pd.to_datetime(weather_data['start_date'])\n        weather_data.set_index(['start_date', 'RES_NAME'], inplace=True)\n\n        # Merge datasets\n        combined_data = pd.merge(evap_data, weather_data, left_index=True, right_index=True)\n\n        return combined_data\n    else:\n        print(f\"Error: {evap_response.status_code} or {weather_response.status_code}\")\n        return None\n\n# Example usage\ncombined_data = combine_datasets(\"LAKE MEAD\", \"2020-06-01\", \"2020-08-31\")\ncombined_data.reset_index(inplace=True)\n\n# Calculate correlation between variables\ncorrelation = combined_data[['NetE (mm)', 'tmmx_c (degC)', 'vpd_kpa (kpa)', 'srad (wm2)']].corr()\nprint(\"Correlation Matrix:\")\nprint(correlation)\n\n# Plot relationship between temperature and evaporation\nplt.figure(figsize=(10, 6))\nplt.scatter(combined_data['tmmx_c (degC)'], combined_data['NetE (mm)'])\nplt.title('Relationship Between Maximum Temperature and Net Evaporation')\nplt.xlabel('Maximum Temperature (\u00b0C)')\nplt.ylabel('Net Evaporation (mm/day)')\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n</code></pre> <pre><code>combine_datasets &lt;- function(reservoir_name, start_date, end_date) {\n  # Combine evaporation and weather data for analysis\n\n  # Get evaporation data\n  evap_url &lt;- paste0(BASE_URL, \"/timeseries/daily/reservoirs/daterange\")\n  evap_params &lt;- list(\n    RES_NAMES = reservoir_name,\n    datasets = \"nete-volume-calcs\",\n    variables = \"NetE,E_volume\",\n    start_date = start_date,\n    end_date = end_date,\n    units = \"metric\",\n    output_format = \"json\"\n  )\n\n  evap_response &lt;- GET(evap_url, HEADERS, query = evap_params)\n\n  # Get weather data\n  weather_url &lt;- paste0(BASE_URL, \"/timeseries/daily/reservoirs/daterange\")\n  weather_params &lt;- list(\n    RES_NAMES = reservoir_name,\n    datasets = \"rtma\",\n    variables = \"pr,tmmx_c,tmmn_c,vpd_kpa,srad\",\n    start_date = start_date,\n    end_date = end_date,\n    units = \"metric\",\n    output_format = \"json\"\n  )\n\n  weather_response &lt;- GET(weather_url, HEADERS, query = weather_params)\n\n  if (status_code(evap_response) == 200 &amp;&amp; status_code(weather_response) == 200) {\n    evap_data &lt;- as.data.frame(fromJSON(content(evap_response, \"text\", encoding = \"UTF-8\")))\n    weather_data &lt;- as.data.frame(fromJSON(content(weather_response, \"text\", encoding = \"UTF-8\")))\n\n    # Prepare data\n    evap_data$start_date &lt;- as.Date(evap_data$start_date)\n    weather_data$start_date &lt;- as.Date(weather_data$start_date)\n\n    # Merge datasets\n    combined_data &lt;- inner_join(\n      evap_data,\n      weather_data,\n      by = c(\"start_date\", \"RES_NAME\")\n    )\n\n    return(combined_data)\n  } else {\n    print(paste(\"Error:\", status_code(evap_response), \"or\", status_code(weather_response)))\n    return(NULL)\n  }\n}\n\n# Example usage\ncombined_data &lt;- combine_datasets(\"LAKE MEAD\", \"2020-06-01\", \"2020-08-31\")\n\n# Calculate the correlation between variables\ncorrelation &lt;- cor(combined_data[, c(\"NetE (mm)\", \"tmmx_c (degC)\", \"vpd_kpa (kpa)\", \"srad (wm2)\")],\n                   use = \"complete.obs\")\ncat(\"Correlation Matrix:\\n\")\nprint(correlation)\n\n# Plot the relationship between temperature and evaporation\nggplot(combined_data, aes(x = tmmx_c (degC), y = NetE (mm))) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = TRUE, color = \"blue\") +\n  labs(\n    title = \"Relationship Between Maximum Temperature and Net Evaporation\",\n    x = \"Maximum Temperature (\u00b0C)\",\n    y = \"Net Evaporation (mm/day)\"\n  ) +\n  theme_minimal() +\n  theme(\n    panel.grid = element_line(color = \"gray90\"),\n    plot.title = element_text(hjust = 0.5)\n  )\n</code></pre> <pre><code># Get evaporation data\ncurl -X GET \"${BASE_URL}/timeseries/daily/reservoirs/daterange?RES_NAMES=LAKE%20MEAD&amp;datasets=nete-volume-calcs&amp;variables=NetE,E_volume&amp;start_date=2020-06-01&amp;end_date=2020-08-31&amp;units=metric&amp;output_format=json\" \\\n     -H \"api-key: ${API_KEY}\" &gt; evap_data.json\n\n# Get weather data\ncurl -X GET \"${BASE_URL}/timeseries/daily/reservoirs/daterange?RES_NAMES=LAKE%20MEAD&amp;datasets=rtma&amp;variables=pr,tmmx_c,tmmn_c,vpd_kpa,srad&amp;start_date=2020-06-01&amp;end_date=2020-08-31&amp;units=metric&amp;output_format=json\" \\\n     -H \"api-key: ${API_KEY}\" &gt; weather_data.json\n\n# Note: Further processing would need to be done with tools like jq or imported into another tool\n</code></pre>"},{"location":"examples/#exporting-data-to-csv","title":"Exporting Data to CSV","text":"PythonRcURL <pre><code>def export_data_to_csv(reservoir_names, start_date, end_date, output_file):\n    \"\"\"Export data for multiple reservoirs to CSV.\"\"\"\n    url = f\"{BASE_URL}/timeseries/daily/reservoirs/daterange\"\n    params = {\n        \"RES_NAMES\": \",\".join(reservoir_names),\n        \"datasets\": \"nete-volume-calcs\",\n        \"variables\": \"NetE,E_volume\",\n        \"start_date\": start_date,\n        \"end_date\": end_date,\n        \"units\": \"metric\",\n        \"output_format\": \"json\"\n    }\n\n    response = requests.get(url, headers=HEADERS, params=params)\n\n    if response.status_code == 200:\n        data = response.json()\n        df = pd.DataFrame(data)\n        df.to_csv(output_file, index=False)\n        print(f\"Data exported to {output_file}\")\n        return True\n    else:\n        print(f\"Error: {response.status_code}\")\n        return False\n\n# Example usage\nreservoir_list = [\"LAKE POWELL\", \"LAKE MEAD\", \"FLAMING GORGE RESERVOIR\"]\nexport_data_to_csv(reservoir_list, \"2020-01-01\", \"2020-12-31\", \"colorado_river_basin_evaporation_2020.csv\")\n</code></pre> <pre><code>export_data_to_csv &lt;- function(reservoir_names, start_date, end_date, output_file) {\n  # Export data for multiple reservoirs to CSV\n  url &lt;- paste0(BASE_URL, \"/timeseries/daily/reservoirs/daterange\")\n  params &lt;- list(\n    RES_NAMES = paste(reservoir_names, collapse = \",\"),\n    datasets = \"nete-volume-calcs\",\n    variables = \"NetE,E_volume\",\n    start_date = start_date,\n    end_date = end_date,\n    units = \"metric\",\n    output_format = \"json\"\n  )\n\n  response &lt;- GET(url, HEADERS, query = params)\n\n  if (status_code(response) == 200) {\n    data &lt;- fromJSON(content(response, \"text\", encoding = \"UTF-8\"))\n    df &lt;- as.data.frame(data)\n    write.csv(df, file = output_file, row.names = FALSE)\n    cat(paste(\"Data exported to\", output_file, \"\\n\"))\n    return(TRUE)\n  } else {\n    cat(paste(\"Error:\", status_code(response), \"\\n\"))\n    return(FALSE)\n  }\n}\n\n# Example usage\nreservoir_list &lt;- c(\"LAKE POWELL\", \"LAKE MEAD\", \"FLAMING GORGE RESERVOIR\")\nexport_data_to_csv(reservoir_list, \"2020-01-01\", \"2020-12-31\", \"colorado_river_basin_evaporation_2020.csv\")\n</code></pre> <pre><code># Export data to a file\ncurl -X GET \"${BASE_URL}/timeseries/daily/reservoirs/daterange?RES_NAMES=LAKE%20POWELL,LAKE%20MEAD,FLAMING%20GORGE%20RESERVOIR&amp;datasets=nete-volume-calcs&amp;variables=NetE,E_volume&amp;start_date=2020-01-01&amp;end_date=2020-12-31&amp;units=metric&amp;output_format=csv\" \\\n     -H \"api-key: ${API_KEY}\" &gt; colorado_river_basin_evaporation_2020.csv\n</code></pre> <p>These examples demonstrate common use cases for the Reservoir Evaporation API and provide a starting point for your own analysis. You can modify and extend these examples to suit your specific needs.</p>"},{"location":"faq/","title":"Frequently Asked Questions","text":""},{"location":"faq/#how-can-i-access-the-data","title":"How can I access the data?","text":"<p>There are three ways to access the data:</p> <ol> <li> <p>The web application for data visualization    https://dri-apps.earthengine.app/view/bor-reservoir-evaporation</p> </li> <li> <p>The API Playground for data inspection    https://operevap.dri.edu</p> </li> <li> <p>The API for data access in production    https://samapriya.github.io/over-evap/ \u2192 Change this link once it has moved to the proper location</p> </li> </ol>"},{"location":"faq/#how-do-i-cite-this-dataset","title":"How do I cite this dataset?","text":""},{"location":"faq/#data-citation","title":"Data citation:","text":"<ul> <li>COOL NAME HERE. (year). Desert Research Institute. Texas A&amp;M, Virginia Tech University and Bureau of Reclamation. Accessed on (date). http://COOLNAME HERE.org. Version 2.1.</li> </ul>"},{"location":"faq/#related-dlem-scientific-publications","title":"Related DLEM Scientific Publications:","text":"<p>Zhao, G., &amp; Gao, H. (2019). Estimating reservoir evaporation losses for the United States: Fusing remote sensing and modeling approaches. Remote Sensing of Environment, 226, 109-124.</p> <p>Zhao, B., Huntington, J., Pearson, C., Zhao, G., Ott, T., Zhu, J., ... &amp; Gao, H. (2024). Developing a general Daily Lake Evaporation Model and demonstrating its application in the state of Texas. Water Resources Research, 60(3), e2023WR036181.</p>"},{"location":"faq/#how-often-is-data-updated","title":"How often is data updated?","text":"<p>The reservoir evaporation database is updated daily; however, the gridded weather forcing data is produced with a 2-day latency leading to a 3-day lag between today and current estimates. We are currently exploring alternative weather datasets to reduce the lag in evaporation estimates.</p>"},{"location":"faq/#my-dataset-shows-negative-evaporation-rates","title":"My dataset shows negative evaporation rates?","text":"<p>Negative evaporation (or condensation) occurs when the temperature of the water body falls below the dew point of the air above (cold water; moist air). Many models neglect to capture this process, but at certain reservoirs during certain time periods, condensation can account for a substantial portion of a reservoir's water balance. DLEM showed good agreement with negative evaporation estimates from Eddy Covariance at Lake Limestone, TX and other locations.</p> <p></p>"},{"location":"faq/#data-i-downloaded-previously-changed","title":"Data I downloaded previously changed?","text":"<p>The input weather dataset used by DLEM provides provisional estimates for ~2 months to allow for review and updates. The reservoir evaporation database updates the last 2-months of data each day to incorporate changes in the forcing data and gather in-situ data that may not have been available during the initial model run. Early, Provisional, and Final data flags are included with each daily estimate for tracking.</p>"},{"location":"faq/#my-reservoir-shows-static-values-for-area-elevation-and-volume","title":"My reservoir shows static values for area, elevation, and volume?","text":"<p>Area, elevation, and volume information is not available in real-time for all reservoirs. For static locations, we assume area, depth, and volume based on conditions at full storage. If you have area, elevation, and volume information you'd like incorporated, please contact our team @ XXXXXXX.</p>"},{"location":"faq/#reservoir-area-elevation-and-volume-values-disagree-with-internal-or-operational-estimates-from-my-agency","title":"Reservoir area, elevation, and volume values disagree with internal or operational estimates from my agency?","text":"<p>Reservoir AEV information is collated from numerous online databases and resources (see sources documentation here). In many cases, reservoir Area-Elevation-Volume information is updated based and updated bathymetric survey data that may not align with historical estimates. For consistency amongst each evaporation timeseries, the XXXX workflow uses elevation combined with the latest available AEV curves to estimate volume and area. Stakeholders should use the best available judgement when applying estimates and may choose to overwrite area, elevation, and volume information as needed.</p> <p>Note</p> <p>Depths greater than 20 m are treated the same within the DLEM heat storage routine; however, depths less than 20 meters are considered and will influence evaporation estimates.</p>"},{"location":"faq/#how-can-i-obtain-an-api-key","title":"How can I obtain an API key?","text":"<ol> <li>Go to https://operevap.dri.edu</li> <li>Click the down arrow by auth/request_key</li> <li>Click on \"Try it out\"</li> <li>Fill out the form</li> <li>Click 'Execute'</li> <li>Your API key will be issued within 24 hours via email</li> </ol>"},{"location":"faq/#what-do-the-data-flags-mean","title":"What do the data flags mean?","text":"<p>If you run a data request with the option <code>also_return=qflag</code>, you will see a qflag property in the return. This property is data quality flag:</p> <ul> <li>O: raw data value from data sites</li> <li>M: data was not available for this date and is filled with previous date data value</li> <li>S: data point is static</li> <li>R: removed outlier data</li> </ul>"},{"location":"installation/","title":"Installation","text":"<p>PhenoFetch can be installed easily using pip, or directly from the source code.</p>"},{"location":"installation/#prerequisites","title":"Prerequisites","text":"<p>Before installing PhenoFetch, ensure you have the following prerequisites:</p> <ul> <li>Python 3.9 or higher</li> <li>pip (Python package installer)</li> </ul>"},{"location":"installation/#install-via-pip","title":"Install via pip","text":"<p>The simplest way to install PhenoFetch is through pip:</p> <pre><code>pip install phenofetch\n</code></pre> <p>To upgrade to the latest version:</p> <pre><code>pip install --upgrade phenofetch\n</code></pre>"},{"location":"installation/#install-from-source","title":"Install from source","text":"<p>If you prefer to install from source or want to contribute to the development:</p> <ol> <li> <p>Clone the repository:    <pre><code>git clone https://github.com/samapriya/phenofetch.git\ncd phenofetch\n</code></pre></p> </li> <li> <p>Install in development mode:    <pre><code>pip install -e .\n</code></pre></p> </li> </ol>"},{"location":"installation/#dependencies","title":"Dependencies","text":"<p>PhenoFetch relies on the following Python packages (these will be automatically installed with pip):</p> <ul> <li>requests &gt;= 2.28.0</li> <li>beautifulsoup4 &gt;= 4.11.0</li> <li>aiofiles &gt;= 0.8.0</li> <li>aiohttp &gt;= 3.8.0</li> <li>psutil &gt;= 5.9.0</li> <li>rich &gt;= 12.0.0</li> <li>tqdm &gt;= 4.64.0</li> <li>colorama &gt;= 0.4.4</li> </ul>"},{"location":"installation/#verification","title":"Verification","text":"<p>To verify that PhenoFetch was installed correctly, run:</p> <pre><code>phenofetch --help\n</code></pre> <p>You should see the help menu with all available commands.</p>"},{"location":"installation/#common-installation-issues","title":"Common Installation Issues","text":""},{"location":"installation/#permission-denied-errors","title":"Permission denied errors","text":"<p>If you encounter permission errors while installing, try using:</p> <pre><code>pip install --user phenofetch\n</code></pre>"},{"location":"installation/#package-not-found-after-installation","title":"Package not found after installation","text":"<p>If the <code>phenofetch</code> command is not found after installation, ensure that your Python scripts directory is in your system PATH.</p> <p>For most systems, you can check where pip installs executables with:</p> <pre><code>pip show phenofetch\n</code></pre> <p>Then add the relevant bin directory to your PATH if necessary.</p>"},{"location":"installation/#incompatible-python-version","title":"Incompatible Python version","text":"<p>PhenoFetch requires Python 3.9 or higher. If you're using an older version, you'll need to upgrade your Python installation.</p>"},{"location":"license/","title":"License","text":"<pre><code>Apache License\nVersion 2.0, January 2004\nhttp://www.apache.org/licenses/\n</code></pre> <p>TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION</p> <ol> <li> <p>Definitions.</p> <p>\"License\" shall mean the terms and conditions for use, reproduction,   and distribution as defined by Sections 1 through 9 of this document.</p> <p>\"Licensor\" shall mean the copyright owner or entity authorized by   the copyright owner that is granting the License.</p> <p>\"Legal Entity\" shall mean the union of the acting entity and all   other entities that control, are controlled by, or are under common   control with that entity. For the purposes of this definition,   \"control\" means (i) the power, direct or indirect, to cause the   direction or management of such entity, whether by contract or   otherwise, or (ii) ownership of fifty percent (50%) or more of the   outstanding shares, or (iii) beneficial ownership of such entity.</p> <p>\"You\" (or \"Your\") shall mean an individual or Legal Entity   exercising permissions granted by this License.</p> <p>\"Source\" form shall mean the preferred form for making modifications,   including but not limited to software source code, documentation   source, and configuration files.</p> <p>\"Object\" form shall mean any form resulting from mechanical   transformation or translation of a Source form, including but   not limited to compiled object code, generated documentation,   and conversions to other media types.</p> <p>\"Work\" shall mean the work of authorship, whether in Source or   Object form, made available under the License, as indicated by a   copyright notice that is included in or attached to the work   (an example is provided in the Appendix below).</p> <p>\"Derivative Works\" shall mean any work, whether in Source or Object   form, that is based on (or derived from) the Work and for which the   editorial revisions, annotations, elaborations, or other modifications   represent, as a whole, an original work of authorship. For the purposes   of this License, Derivative Works shall not include works that remain   separable from, or merely link (or bind by name) to the interfaces of,   the Work and Derivative Works thereof.</p> <p>\"Contribution\" shall mean any work of authorship, including   the original version of the Work and any modifications or additions   to that Work or Derivative Works thereof, that is intentionally   submitted to Licensor for inclusion in the Work by the copyright owner   or by an individual or Legal Entity authorized to submit on behalf of   the copyright owner. For the purposes of this definition, \"submitted\"   means any form of electronic, verbal, or written communication sent   to the Licensor or its representatives, including but not limited to   communication on electronic mailing lists, source code control systems,   and issue tracking systems that are managed by, or on behalf of, the   Licensor for the purpose of discussing and improving the Work, but   excluding communication that is conspicuously marked or otherwise   designated in writing by the copyright owner as \"Not a Contribution.\"</p> <p>\"Contributor\" shall mean Licensor and any individual or Legal Entity   on behalf of whom a Contribution has been received by Licensor and   subsequently incorporated within the Work.</p> </li> <li> <p>Grant of Copyright License. Subject to the terms and conditions of       this License, each Contributor hereby grants to You a perpetual,       worldwide, non-exclusive, no-charge, royalty-free, irrevocable       copyright license to reproduce, prepare Derivative Works of,       publicly display, publicly perform, sublicense, and distribute the       Work and such Derivative Works in Source or Object form.</p> </li> <li> <p>Grant of Patent License. Subject to the terms and conditions of       this License, each Contributor hereby grants to You a perpetual,       worldwide, non-exclusive, no-charge, royalty-free, irrevocable       (except as stated in this section) patent license to make, have made,       use, offer to sell, sell, import, and otherwise transfer the Work,       where such license applies only to those patent claims licensable       by such Contributor that are necessarily infringed by their       Contribution(s) alone or by combination of their Contribution(s)       with the Work to which such Contribution(s) was submitted. If You       institute patent litigation against any entity (including a       cross-claim or counterclaim in a lawsuit) alleging that the Work       or a Contribution incorporated within the Work constitutes direct       or contributory patent infringement, then any patent licenses       granted to You under this License for that Work shall terminate       as of the date such litigation is filed.</p> </li> <li> <p>Redistribution. You may reproduce and distribute copies of the       Work or Derivative Works thereof in any medium, with or without       modifications, and in Source or Object form, provided that You       meet the following conditions:</p> <p>(a) You must give any other recipients of the Work or       Derivative Works a copy of this License; and</p> <p>(b) You must cause any modified files to carry prominent notices       stating that You changed the files; and</p> <p>\u00a9 You must retain, in the Source form of any Derivative Works       that You distribute, all copyright, patent, trademark, and       attribution notices from the Source form of the Work,       excluding those notices that do not pertain to any part of       the Derivative Works; and</p> <p>(d) If the Work includes a \"NOTICE\" text file as part of its       distribution, then any Derivative Works that You distribute must       include a readable copy of the attribution notices contained       within such NOTICE file, excluding those notices that do not       pertain to any part of the Derivative Works, in at least one       of the following places: within a NOTICE text file distributed       as part of the Derivative Works; within the Source form or       documentation, if provided along with the Derivative Works; or,       within a display generated by the Derivative Works, if and       wherever such third-party notices normally appear. The contents       of the NOTICE file are for informational purposes only and       do not modify the License. You may add Your own attribution       notices within Derivative Works that You distribute, alongside       or as an addendum to the NOTICE text from the Work, provided       that such additional attribution notices cannot be construed       as modifying the License.</p> <p>You may add Your own copyright statement to Your modifications and   may provide additional or different license terms and conditions   for use, reproduction, or distribution of Your modifications, or   for any such Derivative Works as a whole, provided Your use,   reproduction, and distribution of the Work otherwise complies with   the conditions stated in this License.</p> </li> <li> <p>Submission of Contributions. Unless You explicitly state otherwise,       any Contribution intentionally submitted for inclusion in the Work       by You to the Licensor shall be under the terms and conditions of       this License, without any additional terms or conditions.       Notwithstanding the above, nothing herein shall supersede or modify       the terms of any separate license agreement you may have executed       with Licensor regarding such Contributions.</p> </li> <li> <p>Trademarks. This License does not grant permission to use the trade       names, trademarks, service marks, or product names of the Licensor,       except as required for reasonable and customary use in describing the       origin of the Work and reproducing the content of the NOTICE file.</p> </li> <li> <p>Disclaimer of Warranty. Unless required by applicable law or       agreed to in writing, Licensor provides the Work (and each       Contributor provides its Contributions) on an \"AS IS\" BASIS,       WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or       implied, including, without limitation, any warranties or conditions       of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A       PARTICULAR PURPOSE. You are solely responsible for determining the       appropriateness of using or redistributing the Work and assume any       risks associated with Your exercise of permissions under this License.</p> </li> <li> <p>Limitation of Liability. In no event and under no legal theory,       whether in tort (including negligence), contract, or otherwise,       unless required by applicable law (such as deliberate and grossly       negligent acts) or agreed to in writing, shall any Contributor be       liable to You for damages, including any direct, indirect, special,       incidental, or consequential damages of any character arising as a       result of this License or out of the use or inability to use the       Work (including but not limited to damages for loss of goodwill,       work stoppage, computer failure or malfunction, or any and all       other commercial damages or losses), even if such Contributor       has been advised of the possibility of such damages.</p> </li> <li> <p>Accepting Warranty or Additional Liability. While redistributing       the Work or Derivative Works thereof, You may choose to offer,       and charge a fee for, acceptance of support, warranty, indemnity,       or other liability obligations and/or rights consistent with this       License. However, in accepting such obligations, You may act only       on Your own behalf and on Your sole responsibility, not on behalf       of any other Contributor, and only if You agree to indemnify,       defend, and hold each Contributor harmless for any liability       incurred by, or claims asserted against, such Contributor by reason       of your accepting any such warranty or additional liability.</p> </li> </ol> <p>END OF TERMS AND CONDITIONS</p> <p>APPENDIX: How to apply the Apache License to your work.</p> <pre><code>  To apply the Apache License to your work, attach the following\n  boilerplate notice, with the fields enclosed by brackets \"{}\"\n  replaced with your own identifying information. (Don't include\n  the brackets!)  The text should be enclosed in the appropriate\n  comment syntax for the file format. We also recommend that a\n  file or class name and description of purpose be included on the\n  same \"printed page\" as the copyright notice for easier\n  identification within third-party archives.\n</code></pre> <p>Copyright {2025} {Samapriya Roy}</p> <p>Licensed under the Apache License, Version 2.0 (the \"License\");    you may not use this file except in compliance with the License.    You may obtain a copy of the License at</p> <pre><code>   http://www.apache.org/licenses/LICENSE-2.0\n</code></pre> <p>Unless required by applicable law or agreed to in writing, software    distributed under the License is distributed on an \"AS IS\" BASIS,    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.    See the License for the specific language governing permissions and    limitations under the License.</p>"},{"location":"usage/","title":"Usage","text":"<p>PhenoFetch provides a straightforward command-line interface for downloading and analyzing PhenoCam data. This page covers the basic usage patterns and common workflows.</p>"},{"location":"usage/#command-structure","title":"Command Structure","text":"<p>All PhenoFetch commands follow this basic structure:</p> <pre><code>phenofetch [command] [options]\n</code></pre> <p>The main commands are:</p> <ul> <li><code>sites</code> - List all available PhenoCam sites</li> <li><code>stats</code> - Display statistics for a site</li> <li><code>estimate</code> - Estimate download size for a date range</li> <li><code>download</code> - Download data for a specific site and date range</li> </ul>"},{"location":"usage/#getting-help","title":"Getting Help","text":"<p>To see all available commands and options:</p> <pre><code>phenofetch --help\n</code></pre> <p>For help with a specific command:</p> <pre><code>phenofetch [command] --help\n</code></pre>"},{"location":"usage/#common-arguments","title":"Common Arguments","text":"<p>Many commands share common arguments:</p> <ul> <li><code>--site</code> - NEON site code (e.g., ABBY, BART)</li> <li><code>--product</code> - NEON product ID (e.g., DP1.00033)</li> <li><code>--start-date</code> - Start date in YYYY-MM-DD format</li> <li><code>--end-date</code> - End date in YYYY-MM-DD format</li> </ul>"},{"location":"usage/#basic-workflow","title":"Basic Workflow","text":"<p>A typical workflow with PhenoFetch might look like this:</p> <ol> <li> <p>Discover available sites:    <pre><code>phenofetch sites\n</code></pre></p> </li> <li> <p>Check site statistics to understand data availability:    <pre><code>phenofetch stats --site HARV --product DP1.00033\n</code></pre></p> </li> <li> <p>Estimate download size before committing to a large download:    <pre><code>phenofetch estimate --site ABBY --product DP1.00033 --start-date 2022-01-01 --end-date 2022-01-31\n</code></pre></p> </li> <li> <p>Download the data:    <pre><code>phenofetch download --site ABBY --product DP1.00033 --start-date 2022-01-01 --end-date 2022-01-31 --download --output-dir ./my_phenocam_data\n</code></pre></p> </li> </ol>"},{"location":"usage/#understanding-download-output","title":"Understanding Download Output","text":"<p>When downloading data, PhenoFetch will create a directory structure that preserves the organization of the files:</p> <pre><code>output_dir/\n\u251c\u2500\u2500 full_res/\n\u2502   \u251c\u2500\u2500 image1.jpg\n\u2502   \u251c\u2500\u2500 image2.jpg\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 thumbnails/\n\u2502   \u251c\u2500\u2500 thumb1.jpg\n\u2502   \u251c\u2500\u2500 thumb2.jpg\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 meta/\n    \u251c\u2500\u2500 metadata1.meta\n    \u251c\u2500\u2500 metadata2.meta\n    \u2514\u2500\u2500 ...\n</code></pre> <ul> <li><code>full_res/</code> - Contains full-resolution images</li> <li><code>thumbnails/</code> - Contains thumbnail images</li> <li><code>meta/</code> - Contains metadata files</li> </ul>"},{"location":"usage/#managing-downloads","title":"Managing Downloads","text":"<p>PhenoFetch provides several options to manage downloads effectively:</p> <ul> <li> <p>Batch size: Control how many files are processed in each batch   <pre><code>--batch-size 100\n</code></pre></p> </li> <li> <p>Concurrency: Set maximum number of concurrent downloads (by default, this is auto-determined based on your system resources)   <pre><code>--concurrency 8\n</code></pre></p> </li> <li> <p>Timeout: Set connection timeout in seconds   <pre><code>--timeout 60\n</code></pre></p> </li> </ul>"},{"location":"usage/#preview-mode","title":"Preview Mode","text":"<p>To see what files would be downloaded without actually downloading them:</p> <pre><code>phenofetch download --site ABBY --product DP1.00033 --start-date 2022-01-01 --end-date 2022-01-31\n</code></pre> <p>Note that omitting the <code>--download</code> flag will only show a summary of available files.</p>"},{"location":"endpoints/info-endpoints/","title":"Info Endpoints","text":"<p>The Info/Help endpoints provide information about the available data in the API, including datasets, variables, reservoirs, stations, and date ranges. These endpoints are useful for discovering what data is available and how to access it.</p>"},{"location":"endpoints/info-endpoints/#list-available-datasets","title":"List Available Datasets","text":"<p>Lists all available datasets in the API.</p> PythonRcURL <pre><code>import requests\n\nurl = \"https://operevap.dri.edu/info/list_datasets\"\nheaders = {\n    \"api-key\": \"YOUR_API_KEY\"\n}\nparams = {\n    \"output_format\": \"json\"  # or \"csv\"\n}\n\nresponse = requests.get(url, headers=headers, params=params)\ndata = response.json()\nprint(data)\n</code></pre> <pre><code>library(httr)\nlibrary(jsonlite)\n\n# API configuration\napi_key &lt;- \"YOUR_API_KEY\"\nbase_url &lt;- \"https://operevap.dri.edu\"\n\n# Get available datasets\nurl &lt;- paste0(base_url, \"/info/list_datasets\")\n\nresponse &lt;- GET(\n  url,\n  add_headers(\"api-key\" = api_key),\n  query = list(output_format = \"json\")\n)\n\n# Parse response\ndata &lt;- fromJSON(content(response, \"text\", encoding = \"UTF-8\"))\nprint(data)\n</code></pre> <pre><code># Set your API key\nAPI_KEY=\"YOUR_API_KEY\"\n\n# Get available datasets\ncurl -X GET \"https://operevap.dri.edu/info/list_datasets?output_format=json\" \\\n     -H \"api-key: ${API_KEY}\"\n</code></pre>"},{"location":"endpoints/info-endpoints/#parameters","title":"Parameters","text":"Parameter Type Description Default output_format string Response format (json or csv) json"},{"location":"endpoints/info-endpoints/#response","title":"Response","text":"<p>Returns a list of dataset names that can be used as the <code>dataset</code> parameter in other API requests.</p>"},{"location":"endpoints/info-endpoints/#list-available-variables","title":"List Available Variables","text":"<p>Lists available variables for a specified dataset.</p> PythonRcURL <pre><code>import requests\n\nurl = \"https://operevap.dri.edu/info/list_variables\"\nheaders = {\n    \"api-key\": \"YOUR_API_KEY\"\n}\nparams = {\n    \"output_format\": \"json\",  # or \"csv\"\n    \"dataset\": \"nete-volume-calcs\"  # Dataset name\n}\n\nresponse = requests.get(url, headers=headers, params=params)\ndata = response.json()\nprint(data)\n</code></pre> <pre><code>library(httr)\nlibrary(jsonlite)\n\n# API configuration\napi_key &lt;- \"YOUR_API_KEY\"\nbase_url &lt;- \"https://operevap.dri.edu\"\n\n# Get available variables for a dataset\nurl &lt;- paste0(base_url, \"/info/list_variables\")\n\nresponse &lt;- GET(\n  url,\n  add_headers(\"api-key\" = api_key),\n  query = list(\n    output_format = \"json\",\n    dataset = \"nete-volume-calcs\"\n  )\n)\n\n# Parse response\ndata &lt;- fromJSON(content(response, \"text\", encoding = \"UTF-8\"))\nprint(data)\n</code></pre> <pre><code># Set your API key\nAPI_KEY=\"YOUR_API_KEY\"\n\n# Get available variables for a dataset\ncurl -X GET \"https://operevap.dri.edu/info/list_variables?output_format=json&amp;dataset=nete-volume-calcs\" \\\n     -H \"api-key: ${API_KEY}\"\n</code></pre>"},{"location":"endpoints/info-endpoints/#parameters_1","title":"Parameters","text":"Parameter Type Description Default output_format string Response format (json or csv) json dataset string Dataset name (rtma, res, lem, nete-volume-calcs) nete-volume-calcs"},{"location":"endpoints/info-endpoints/#response_1","title":"Response","text":"<p>Returns a list of dictionaries containing variable information. The <code>api_name</code> field in each dictionary can be used as the <code>variable</code> parameter in other API requests.</p>"},{"location":"endpoints/info-endpoints/#list-date-range","title":"List Date Range","text":"<p>Lists the minimum and maximum dates available for a dataset and variable.</p> PythonRcURL <pre><code>import requests\n\nurl = \"https://operevap.dri.edu/info/list_dates\"\nheaders = {\n    \"api-key\": \"YOUR_API_KEY\"\n}\nparams = {\n    \"output_format\": \"json\",  # or \"csv\"\n    \"dataset\": \"nete-volume-calcs\",\n    \"variable\": \"NetE\"\n}\n\nresponse = requests.get(url, headers=headers, params=params)\ndata = response.json()\nprint(data)\n</code></pre> <pre><code>library(httr)\nlibrary(jsonlite)\n\n# API configuration\napi_key &lt;- \"YOUR_API_KEY\"\nbase_url &lt;- \"https://operevap.dri.edu\"\n\n# Get date range for a dataset and variable\nurl &lt;- paste0(base_url, \"/info/list_dates\")\n\nresponse &lt;- GET(\n  url,\n  add_headers(\"api-key\" = api_key),\n  query = list(\n    output_format = \"json\",\n    dataset = \"nete-volume-calcs\",\n    variable = \"NetE\"\n  )\n)\n\n# Parse response\ndata &lt;- fromJSON(content(response, \"text\", encoding = \"UTF-8\"))\nprint(data)\n</code></pre> <pre><code># Set your API key\nAPI_KEY=\"YOUR_API_KEY\"\n\n# Get date range for a dataset and variable\ncurl -X GET \"https://operevap.dri.edu/info/list_dates?output_format=json&amp;dataset=nete-volume-calcs&amp;variable=NetE\" \\\n     -H \"api-key: ${API_KEY}\"\n</code></pre>"},{"location":"endpoints/info-endpoints/#parameters_2","title":"Parameters","text":"Parameter Type Description Default output_format string Response format (json or csv) json dataset string Dataset name (rtma, res, lem, nete-volume-calcs) nete-volume-calcs variable string Variable name (see list_variables endpoint) NetE"},{"location":"endpoints/info-endpoints/#response_2","title":"Response","text":"<p>Returns a list containing the start date and end date for the specified dataset and variable.</p>"},{"location":"endpoints/info-endpoints/#list-reservoir-names","title":"List Reservoir Names","text":"<p>Lists available reservoir IDs (RES_NAME) that can be used in other API requests.</p> PythonRcURL <pre><code>import requests\n\nurl = \"https://operevap.dri.edu/info/list_RES_NAMES\"\nheaders = {\n    \"api-key\": \"YOUR_API_KEY\"\n}\nparams = {\n    \"output_format\": \"json\"  # or \"csv\"\n}\n\n# Without shapefile\nresponse = requests.post(url, headers=headers, params=params)\ndata = response.json()\nprint(data)\n\n# With shapefile (if needed)\nfiles = {\n    'shapefile_shp': open('your_shapefile.shp', 'rb'),\n    'shapefile_dbf': open('your_shapefile.dbf', 'rb'),\n    'shapefile_prj': open('your_shapefile.prj', 'rb'),\n    'shapefile_shx': open('your_shapefile.shx', 'rb')\n}\n\nresponse = requests.post(url, headers=headers, params=params, files=files)\ndata = response.json()\nprint(data)\n</code></pre> <pre><code>library(httr)\nlibrary(jsonlite)\n\n# API configuration\napi_key &lt;- \"YOUR_API_KEY\"\nbase_url &lt;- \"https://operevap.dri.edu\"\n\n# Get reservoir names without shapefile\nurl &lt;- paste0(base_url, \"/info/list_RES_NAMES\")\n\nresponse &lt;- POST(\n  url,\n  add_headers(\"api-key\" = api_key),\n  query = list(output_format = \"json\")\n)\n\n# Parse response\ndata &lt;- fromJSON(content(response, \"text\", encoding = \"UTF-8\"))\nprint(data)\n\n# With shapefile (if needed)\nresponse &lt;- POST(\n  url,\n  add_headers(\"api-key\" = api_key),\n  query = list(output_format = \"json\"),\n  body = list(\n    shapefile_shp = upload_file(\"your_shapefile.shp\"),\n    shapefile_dbf = upload_file(\"your_shapefile.dbf\"),\n    shapefile_prj = upload_file(\"your_shapefile.prj\"),\n    shapefile_shx = upload_file(\"your_shapefile.shx\")\n  ),\n  encode = \"multipart\"\n)\n\n# Parse response\ndata &lt;- fromJSON(content(response, \"text\", encoding = \"UTF-8\"))\nprint(data)\n</code></pre> <pre><code># Set your API key\nAPI_KEY=\"YOUR_API_KEY\"\n\n# Get reservoir names without shapefile\ncurl -X POST \"https://operevap.dri.edu/info/list_RES_NAMES?output_format=json\" \\\n     -H \"api-key: ${API_KEY}\"\n\n# Get reservoir names with shapefile (if needed)\ncurl -X POST \"https://operevap.dri.edu/info/list_RES_NAMES?output_format=json\" \\\n     -H \"api-key: ${API_KEY}\" \\\n     -F \"shapefile_shp=@your_shapefile.shp\" \\\n     -F \"shapefile_dbf=@your_shapefile.dbf\" \\\n     -F \"shapefile_prj=@your_shapefile.prj\" \\\n     -F \"shapefile_shx=@your_shapefile.shx\"\n</code></pre>"},{"location":"endpoints/info-endpoints/#parameters_3","title":"Parameters","text":"Parameter Type Description Default output_format string Response format (json or csv) json shapefile_shp file Optional .shp file to filter reservoirs by location shapefile_dbf file Optional .dbf file to filter reservoirs by location shapefile_prj file Optional .prj file to filter reservoirs by location shapefile_shx file Optional .shx file to filter reservoirs by location"},{"location":"endpoints/info-endpoints/#response_3","title":"Response","text":"<p>Returns a list of reservoir names that can be used as the <code>RES_NAMES</code> parameter in metadata and timeseries API requests.</p>"},{"location":"endpoints/info-endpoints/#notes","title":"Notes","text":"<p>If shapefiles are uploaded, only reservoirs within the shapefile bounds will be returned.</p>"},{"location":"endpoints/info-endpoints/#list-station-names","title":"List Station Names","text":"<p>Lists available station IDs (STA_NAME) that can be used in other API requests.</p> PythonRcURL <pre><code>import requests\n\nurl = \"https://operevap.dri.edu/info/list_STA_NAMES\"\nheaders = {\n    \"api-key\": \"YOUR_API_KEY\"\n}\nparams = {\n    \"output_format\": \"json\"  # or \"csv\"\n}\n\n# Without shapefile\nresponse = requests.post(url, headers=headers, params=params)\ndata = response.json()\nprint(data)\n\n# With shapefile (if needed)\nfiles = {\n    'shapefile_shp': open('your_shapefile.shp', 'rb'),\n    'shapefile_dbf': open('your_shapefile.dbf', 'rb'),\n    'shapefile_prj': open('your_shapefile.prj', 'rb'),\n    'shapefile_shx': open('your_shapefile.shx', 'rb')\n}\n\nresponse = requests.post(url, headers=headers, params=params, files=files)\ndata = response.json()\nprint(data)\n</code></pre> <pre><code>library(httr)\nlibrary(jsonlite)\n\n# API configuration\napi_key &lt;- \"YOUR_API_KEY\"\nbase_url &lt;- \"https://operevap.dri.edu\"\n\n# Get station names without shapefile\nurl &lt;- paste0(base_url, \"/info/list_STA_NAMES\")\n\nresponse &lt;- POST(\n  url,\n  add_headers(\"api-key\" = api_key),\n  query = list(output_format = \"json\")\n)\n\n# Parse response\ndata &lt;- fromJSON(content(response, \"text\", encoding = \"UTF-8\"))\nprint(data)\n\n# With shapefile (if needed)\nresponse &lt;- POST(\n  url,\n  add_headers(\"api-key\" = api_key),\n  query = list(output_format = \"json\"),\n  body = list(\n    shapefile_shp = upload_file(\"your_shapefile.shp\"),\n    shapefile_dbf = upload_file(\"your_shapefile.dbf\"),\n    shapefile_prj = upload_file(\"your_shapefile.prj\"),\n    shapefile_shx = upload_file(\"your_shapefile.shx\")\n  ),\n  encode = \"multipart\"\n)\n\n# Parse response\ndata &lt;- fromJSON(content(response, \"text\", encoding = \"UTF-8\"))\nprint(data)\n</code></pre> <pre><code># Set your API key\nAPI_KEY=\"YOUR_API_KEY\"\n\n# Get station names without shapefile\ncurl -X POST \"https://operevap.dri.edu/info/list_STA_NAMES?output_format=json\" \\\n     -H \"api-key: ${API_KEY}\"\n\n# Get station names with shapefile (if needed)\ncurl -X POST \"https://operevap.dri.edu/info/list_STA_NAMES?output_format=json\" \\\n     -H \"api-key: ${API_KEY}\" \\\n     -F \"shapefile_shp=@your_shapefile.shp\" \\\n     -F \"shapefile_dbf=@your_shapefile.dbf\" \\\n     -F \"shapefile_prj=@your_shapefile.prj\" \\\n     -F \"shapefile_shx=@your_shapefile.shx\"\n</code></pre>"},{"location":"endpoints/info-endpoints/#parameters_4","title":"Parameters","text":"Parameter Type Description Default output_format string Response format (json or csv) json shapefile_shp file Optional .shp file to filter stations by location shapefile_dbf file Optional .dbf file to filter stations by location shapefile_prj file Optional .prj file to filter stations by location shapefile_shx file Optional .shx file to filter stations by location"},{"location":"endpoints/info-endpoints/#response_4","title":"Response","text":"<p>Returns a list of station names that can be used as the <code>STA_NAMES</code> parameter in metadata and timeseries API requests.</p>"},{"location":"endpoints/info-endpoints/#notes_1","title":"Notes","text":"<p>If shapefiles are uploaded, only stations within the shapefile bounds will be returned.</p>"},{"location":"endpoints/info-endpoints/#list-station-variables","title":"List Station Variables","text":"<p>Lists available variables for stations.</p> PythonRcURL <pre><code>import requests\n\nurl = \"https://operevap.dri.edu/info/list_stations_variables\"\nheaders = {\n    \"api-key\": \"YOUR_API_KEY\"\n}\nparams = {\n    \"output_format\": \"json\",  # or \"csv\"\n    \"STA_NAMES\": \"ALL_STATIONS\"  # or comma-separated list of station names\n}\n\nresponse = requests.get(url, headers=headers, params=params)\ndata = response.json()\nprint(data)\n</code></pre> <pre><code>library(httr)\nlibrary(jsonlite)\n\n# API configuration\napi_key &lt;- \"YOUR_API_KEY\"\nbase_url &lt;- \"https://operevap.dri.edu\"\n\n# Get station variables\nurl &lt;- paste0(base_url, \"/info/list_stations_variables\")\n\nresponse &lt;- GET(\n  url,\n  add_headers(\"api-key\" = api_key),\n  query = list(\n    output_format = \"json\",\n    STA_NAMES = \"ALL_STATIONS\"  # or comma-separated list of station names\n  )\n)\n\n# Parse response\ndata &lt;- fromJSON(content(response, \"text\", encoding = \"UTF-8\"))\nprint(data)\n</code></pre> <pre><code># Set your API key\nAPI_KEY=\"YOUR_API_KEY\"\n\n# Get station variables\ncurl -X GET \"https://operevap.dri.edu/info/list_stations_variables?output_format=json&amp;STA_NAMES=ALL_STATIONS\" \\\n     -H \"api-key: ${API_KEY}\"\n</code></pre>"},{"location":"endpoints/info-endpoints/#parameters_5","title":"Parameters","text":"Parameter Type Description Default output_format string Response format (json or csv) json STA_NAMES string One or more station names (comma-separated), or ALL_STATIONS ALL_STATIONS"},{"location":"endpoints/info-endpoints/#response_5","title":"Response","text":"<p>Returns a list of dictionaries containing variable information. The <code>api_name</code> field in each dictionary can be used as the <code>variable</code> parameter in other API requests.</p>"},{"location":"endpoints/info-endpoints/#list-station-date-range","title":"List Station Date Range","text":"<p>Lists the minimum and maximum dates available for stations in the database.</p> PythonRcURL <pre><code>import requests\n\nurl = \"https://operevap.dri.edu/info/list_stations_dates\"\nheaders = {\n    \"api-key\": \"YOUR_API_KEY\"\n}\nparams = {\n    \"output_format\": \"json\",  # or \"csv\"\n    \"STA_NAMES\": \"ALL_STATIONS\"  # or comma-separated list of station names\n}\n\nresponse = requests.get(url, headers=headers, params=params)\ndata = response.json()\nprint(data)\n</code></pre> <pre><code>library(httr)\nlibrary(jsonlite)\n\n# API configuration\napi_key &lt;- \"YOUR_API_KEY\"\nbase_url &lt;- \"https://operevap.dri.edu\"\n\n# Get station date range\nurl &lt;- paste0(base_url, \"/info/list_stations_dates\")\n\nresponse &lt;- GET(\n  url,\n  add_headers(\"api-key\" = api_key),\n  query = list(\n    output_format = \"json\",\n    STA_NAMES = \"ALL_STATIONS\"  # or comma-separated list of station names\n  )\n)\n\n# Parse response\ndata &lt;- fromJSON(content(response, \"text\", encoding = \"UTF-8\"))\nprint(data)\n</code></pre> <pre><code># Set your API key\nAPI_KEY=\"YOUR_API_KEY\"\n\n# Get station date range\ncurl -X GET \"https://operevap.dri.edu/info/list_stations_dates?output_format=json&amp;STA_NAMES=ALL_STATIONS\" \\\n     -H \"api-key: ${API_KEY}\"\n</code></pre>"},{"location":"endpoints/info-endpoints/#parameters_6","title":"Parameters","text":"Parameter Type Description Default output_format string Response format (json or csv) json STA_NAMES string One or more station names (comma-separated), or ALL_STATIONS ALL_STATIONS"},{"location":"endpoints/info-endpoints/#response_6","title":"Response","text":"<p>Returns a list containing the start date and end date for the specified stations.</p>"},{"location":"endpoints/metadata-endpoints/","title":"Metadata Endpoints","text":"<p>The metadata endpoints provide information about the reservoirs and stations available in the API. This metadata includes details such as location, physical characteristics, and other attributes.</p>"},{"location":"endpoints/metadata-endpoints/#reservoir-metadata","title":"Reservoir Metadata","text":"<p>Retrieves metadata for one or more reservoirs.</p> PythonRcURL <pre><code>import requests\n\nurl = \"https://operevap.dri.edu/metadata/reservoirs\"\nheaders = {\n    \"api-key\": \"YOUR_API_KEY\"\n}\nparams = {\n    \"RES_NAMES\": \"LAKE ALICE,LAKE ESTES\",\n    \"output_format\": \"json\"\n}\n\nresponse = requests.get(url, headers=headers, params=params)\ndata = response.json()\nprint(data)\n</code></pre> <pre><code>library(httr)\nlibrary(jsonlite)\n\n# API configuration\napi_key &lt;- \"YOUR_API_KEY\"\nbase_url &lt;- \"https://operevap.dri.edu\"\n\n# Get reservoir metadata\nurl &lt;- paste0(base_url, \"/metadata/reservoirs\")\n\nresponse &lt;- GET(\n  url,\n  add_headers(\"api-key\" = api_key),\n  query = list(\n    RES_NAMES = \"LAKE ALICE,LAKE ESTES\",\n    output_format = \"json\"\n  )\n)\n\n# Parse response\ndata &lt;- fromJSON(content(response, \"text\", encoding = \"UTF-8\"))\nprint(data)\n</code></pre> <pre><code># Set your API key\nAPI_KEY=\"YOUR_API_KEY\"\n\n# Get reservoir metadata\ncurl -X GET \"https://operevap.dri.edu/metadata/reservoirs?RES_NAMES=LAKE%20ALICE,LAKE%20ESTES&amp;output_format=json\" \\\n     -H \"api-key: ${API_KEY}\"\n</code></pre>"},{"location":"endpoints/metadata-endpoints/#parameters","title":"Parameters","text":"Parameter Type Description Default output_format string Response format (json or csv) json RES_NAMES string One or more reservoir names (comma-separated) LAKE ALICE, LAKE ESTES"},{"location":"endpoints/metadata-endpoints/#response","title":"Response","text":"<p>Returns a list of dictionaries containing metadata information for the specified reservoirs. The metadata includes attributes such as:</p> <ul> <li>Geographic coordinates (latitude, longitude)</li> <li>Physical characteristics (area, depth, etc.)</li> <li>Administrative information</li> <li>Quality flags (qflag)</li> <li>And other attributes</li> </ul>"},{"location":"endpoints/metadata-endpoints/#notes","title":"Notes","text":"<p>Use the <code>/info/list_RES_NAMES</code> endpoint to discover available reservoir names.</p>"},{"location":"endpoints/metadata-endpoints/#station-metadata","title":"Station Metadata","text":"<p>Retrieves metadata for one or more stations.</p> PythonRcURL <pre><code>import requests\n\nurl = \"https://operevap.dri.edu/metadata/stations\"\nheaders = {\n    \"api-key\": \"YOUR_API_KEY\"\n}\nparams = {\n    \"STA_NAMES\": \"ABERDEEN_STATION,ABIQUIU DAM_STATION\",\n    \"output_format\": \"json\"\n}\n\nresponse = requests.get(url, headers=headers, params=params)\ndata = response.json()\nprint(data)\n</code></pre> <pre><code>library(httr)\nlibrary(jsonlite)\n\n# API configuration\napi_key &lt;- \"YOUR_API_KEY\"\nbase_url &lt;- \"https://operevap.dri.edu\"\n\n# Get station metadata\nurl &lt;- paste0(base_url, \"/metadata/stations\")\n\nresponse &lt;- GET(\n  url,\n  add_headers(\"api-key\" = api_key),\n  query = list(\n    STA_NAMES = \"ABERDEEN_STATION,ABIQUIU DAM_STATION\",\n    output_format = \"json\"\n  )\n)\n\n# Parse response\ndata &lt;- fromJSON(content(response, \"text\", encoding = \"UTF-8\"))\nprint(data)\n</code></pre> <pre><code># Set your API key\nAPI_KEY=\"YOUR_API_KEY\"\n\n# Get station metadata\ncurl -X GET \"https://operevap.dri.edu/metadata/stations?STA_NAMES=ABERDEEN_STATION,ABIQUIU%20DAM_STATION&amp;output_format=json\" \\\n     -H \"api-key: ${API_KEY}\"\n</code></pre>"},{"location":"endpoints/metadata-endpoints/#parameters_1","title":"Parameters","text":"Parameter Type Description Default output_format string Response format (json or csv) json STA_NAMES string One or more station names (comma-separated) ABERDEEN_STATION, ABIQUIU DAM_STATION"},{"location":"endpoints/metadata-endpoints/#response_1","title":"Response","text":"<p>Returns a list of dictionaries containing metadata information for the specified stations. The metadata includes attributes such as:</p> <ul> <li>Geographic coordinates (latitude, longitude)</li> <li>Station type</li> <li>Operational status</li> <li>Associated reservoir (if applicable)</li> <li>Quality flags (qflag)</li> <li>And other attributes</li> </ul>"},{"location":"endpoints/metadata-endpoints/#notes_1","title":"Notes","text":"<p>Use the <code>/info/list_STA_NAMES</code> endpoint to discover available station names.</p>"},{"location":"endpoints/metadata-endpoints/#using-metadata-in-other-requests","title":"Using Metadata in Other Requests","text":"<p>The metadata attributes can be included in timeseries responses by using the <code>also_return</code> parameter in timeseries requests. For example:</p> PythonRcURL <pre><code>import requests\n\nurl = \"https://operevap.dri.edu/timeseries/daily/reservoirs/daterange\"\nheaders = {\n    \"api-key\": \"YOUR_API_KEY\"\n}\nparams = {\n    \"RES_NAMES\": \"LAKE ALICE\",\n    \"datasets\": \"nete-volume-calcs\",\n    \"variables\": \"NetE,E_volume\",\n    \"start_date\": \"2020-01-01\",\n    \"end_date\": \"2020-01-31\",\n    \"units\": \"metric\",\n    \"also_return\": \"qflag\",\n    \"output_format\": \"json\"\n}\n\nresponse = requests.get(url, headers=headers, params=params)\ndata = response.json()\nprint(data)\n</code></pre> <pre><code>library(httr)\nlibrary(jsonlite)\n\n# API configuration\napi_key &lt;- \"YOUR_API_KEY\"\nbase_url &lt;- \"https://operevap.dri.edu\"\n\n# Get timeseries data with metadata attributes\nurl &lt;- paste0(base_url, \"/timeseries/daily/reservoirs/daterange\")\n\nresponse &lt;- GET(\n  url,\n  add_headers(\"api-key\" = api_key),\n  query = list(\n    RES_NAMES = \"LAKE ALICE\",\n    datasets = \"nete-volume-calcs\",\n    variables = \"NetE,E_volume\",\n    start_date = \"2020-01-01\",\n    end_date = \"2020-01-31\",\n    units = \"metric\",\n    also_return = \"qflag\",\n    output_format = \"json\"\n  )\n)\n\n# Parse response\ndata &lt;- fromJSON(content(response, \"text\", encoding = \"UTF-8\"))\nprint(data)\n</code></pre> <pre><code># Set your API key\nAPI_KEY=\"YOUR_API_KEY\"\n\n# Get timeseries data with metadata attributes\ncurl -X GET \"https://operevap.dri.edu/timeseries/daily/reservoirs/daterange?RES_NAMES=LAKE%20ALICE&amp;datasets=nete-volume-calcs&amp;variables=NetE,E_volume&amp;start_date=2020-01-01&amp;end_date=2020-01-31&amp;units=metric&amp;also_return=qflag&amp;output_format=json\" \\\n     -H \"api-key: ${API_KEY}\"\n</code></pre> <p>This is useful for understanding the quality or context of the data returned in timeseries responses.</p>"},{"location":"endpoints/timeseries-endpoints/","title":"Timeseries Endpoints","text":"<p>The timeseries endpoints provide access to time-based data for reservoirs and stations. These endpoints are divided into two categories:</p> <ol> <li>Reservoir timeseries data</li> <li>Station timeseries data</li> </ol> <p>Each category has endpoints for retrieving data over a date range or for a single date.</p>"},{"location":"endpoints/timeseries-endpoints/#reservoir-timeseries-data-date-range","title":"Reservoir Timeseries Data (Date Range)","text":"<p>Retrieves timeseries data for one or more reservoirs over a specified date range.</p> PythonRcURL <pre><code>import requests\n\nurl = \"https://operevap.dri.edu/timeseries/daily/reservoirs/daterange\"\nheaders = {\n    \"api-key\": \"YOUR_API_KEY\"\n}\nparams = {\n    \"RES_NAMES\": \"LAKE ALICE\",\n    \"datasets\": \"nete-volume-calcs\",\n    \"variables\": \"NetE,E_volume\",\n    \"start_date\": \"2020-01-01\",\n    \"end_date\": \"2020-01-31\",\n    \"units\": \"metric\",\n    \"output_format\": \"json\"\n}\n\nresponse = requests.get(url, headers=headers, params=params)\ndata = response.json()\nprint(data)\n</code></pre> <pre><code>library(httr)\nlibrary(jsonlite)\n\n# API configuration\napi_key &lt;- \"YOUR_API_KEY\"\nbase_url &lt;- \"https://operevap.dri.edu\"\n\n# Get reservoir timeseries data\nurl &lt;- paste0(base_url, \"/timeseries/daily/reservoirs/daterange\")\n\nresponse &lt;- GET(\n  url,\n  add_headers(\"api-key\" = api_key),\n  query = list(\n    RES_NAMES = \"LAKE ALICE\",\n    datasets = \"nete-volume-calcs\",\n    variables = \"NetE,E_volume\",\n    start_date = \"2020-01-01\",\n    end_date = \"2020-01-31\",\n    units = \"metric\",\n    output_format = \"json\"\n  )\n)\n\n# Parse response\ndata &lt;- fromJSON(content(response, \"text\", encoding = \"UTF-8\"))\nprint(data)\n</code></pre> <pre><code># Set your API key\nAPI_KEY=\"YOUR_API_KEY\"\n\n# Get reservoir timeseries data\ncurl -X GET \"https://operevap.dri.edu/timeseries/daily/reservoirs/daterange?RES_NAMES=LAKE%20ALICE&amp;datasets=nete-volume-calcs&amp;variables=NetE,E_volume&amp;start_date=2020-01-01&amp;end_date=2020-01-31&amp;units=metric&amp;output_format=json\" \\\n     -H \"api-key: ${API_KEY}\"\n</code></pre>"},{"location":"endpoints/timeseries-endpoints/#parameters","title":"Parameters","text":"Parameter Type Description Default RES_NAMES string One or more reservoir names (comma-separated) LAKE ALICE, LAKE ESTES datasets string One or more datasets (comma-separated) rtma, res, lem, nete-volume-calcs variables string One or more variables (comma-separated) pr, tmmx_c, tmmn_c, vpd_kpa, vs2m, srad, etr, eto, th, sph_kgkg, pres_pa, stage_m, area_m2, depth_m, E_hs, E_nhs, Rn, Tw, Tw0, Fetch, Lerr, NetE, E_volume, NetE_volume units string Units for returned data (english or metric) metric start_date string Start date (yyyy-mm-dd) 2020-01-01 end_date string End date (yyyy-mm-dd) 2020-01-31 also_return string Additional metadata attributes to include in response output_format string Response format (json or csv) json"},{"location":"endpoints/timeseries-endpoints/#response","title":"Response","text":"<p>Returns a list of dictionaries containing timeseries data for the specified reservoirs, datasets, variables, and date range.</p>"},{"location":"endpoints/timeseries-endpoints/#notes","title":"Notes","text":"<ul> <li>Use the <code>/info/list_RES_NAMES</code> endpoint to discover available reservoir names.</li> <li>Use the <code>/info/list_variables</code> endpoint to discover available variables for each dataset.</li> <li>Use the <code>/info/list_dates</code> endpoint to discover the valid date range for each dataset and variable.</li> </ul>"},{"location":"endpoints/timeseries-endpoints/#reservoir-timeseries-data-single-date","title":"Reservoir Timeseries Data (Single Date)","text":"<p>Retrieves timeseries data for all reservoirs on a single date.</p> PythonRcURL <pre><code>import requests\n\nurl = \"https://operevap.dri.edu/timeseries/daily/reservoirs/date\"\nheaders = {\n    \"api-key\": \"YOUR_API_KEY\"\n}\nparams = {\n    \"datasets\": \"nete-volume-calcs\",\n    \"variables\": \"NetE,E_volume\",\n    \"date\": \"2020-01-01\",\n    \"units\": \"metric\",\n    \"output_format\": \"json\"\n}\n\nresponse = requests.get(url, headers=headers, params=params)\ndata = response.json()\nprint(data)\n</code></pre> <pre><code>library(httr)\nlibrary(jsonlite)\n\n# API configuration\napi_key &lt;- \"YOUR_API_KEY\"\nbase_url &lt;- \"https://operevap.dri.edu\"\n\n# Get reservoir data for a single date\nurl &lt;- paste0(base_url, \"/timeseries/daily/reservoirs/date\")\n\nresponse &lt;- GET(\n  url,\n  add_headers(\"api-key\" = api_key),\n  query = list(\n    datasets = \"nete-volume-calcs\",\n    variables = \"NetE,E_volume\",\n    date = \"2020-01-01\",\n    units = \"metric\",\n    output_format = \"json\"\n  )\n)\n\n# Parse response\ndata &lt;- fromJSON(content(response, \"text\", encoding = \"UTF-8\"))\nprint(data)\n</code></pre> <pre><code># Set your API key\nAPI_KEY=\"YOUR_API_KEY\"\n\n# Get reservoir data for a single date\ncurl -X GET \"https://operevap.dri.edu/timeseries/daily/reservoirs/date?datasets=nete-volume-calcs&amp;variables=NetE,E_volume&amp;date=2020-01-01&amp;units=metric&amp;output_format=json\" \\\n     -H \"api-key: ${API_KEY}\"\n</code></pre>"},{"location":"endpoints/timeseries-endpoints/#parameters_1","title":"Parameters","text":"Parameter Type Description Default datasets string One or more datasets (comma-separated) rtma, res, lem, nete-volume-calcs variables string One or more variables (comma-separated) pr, tmmx_c, tmmn_c, vpd_kpa, vs2m, srad, etr, eto, th, sph_kgkg, pres_pa, stage_m, area_m2, depth_m, E_hs, E_nhs, Rn, Tw, Tw0, Fetch, Lerr, NetE, E_volume, NetE_volume units string Units for returned data (english or metric) metric date string Date (yyyy-mm-dd) 2020-01-01 also_return string Additional metadata attributes to include in response output_format string Response format (json or csv) json"},{"location":"endpoints/timeseries-endpoints/#response_1","title":"Response","text":"<p>Returns a list of dictionaries containing timeseries data for all reservoirs for the specified datasets, variables, and date.</p>"},{"location":"endpoints/timeseries-endpoints/#station-timeseries-data-date-range","title":"Station Timeseries Data (Date Range)","text":"<p>Retrieves timeseries data for one or more stations over a specified date range.</p> PythonRcURL <pre><code>import requests\n\nurl = \"https://operevap.dri.edu/timeseries/stations/daterange\"\nheaders = {\n    \"api-key\": \"YOUR_API_KEY\"\n}\nparams = {\n    \"STA_NAMES\": \"LAKE MEAD_STATION\",\n    \"variables\": \"ATemp,RH\",\n    \"start_date\": \"2020-01-01\",\n    \"end_date\": \"2020-01-31\",\n    \"units\": \"metric\",\n    \"output_format\": \"json\"\n}\n\nresponse = requests.get(url, headers=headers, params=params)\ndata = response.json()\nprint(data)\n</code></pre> <pre><code>library(httr)\nlibrary(jsonlite)\n\n# API configuration\napi_key &lt;- \"YOUR_API_KEY\"\nbase_url &lt;- \"https://operevap.dri.edu\"\n\n# Get station timeseries data\nurl &lt;- paste0(base_url, \"/timeseries/stations/daterange\")\n\nresponse &lt;- GET(\n  url,\n  add_headers(\"api-key\" = api_key),\n  query = list(\n    STA_NAMES = \"LAKE MEAD_STATION\",\n    variables = \"ATemp,RH\",\n    start_date = \"2020-01-01\",\n    end_date = \"2020-01-31\",\n    units = \"metric\",\n    output_format = \"json\"\n  )\n)\n\n# Parse response\ndata &lt;- fromJSON(content(response, \"text\", encoding = \"UTF-8\"))\nprint(data)\n</code></pre> <pre><code># Set your API key\nAPI_KEY=\"YOUR_API_KEY\"\n\n# Get station timeseries data\ncurl -X GET \"https://operevap.dri.edu/timeseries/stations/daterange?STA_NAMES=LAKE%20MEAD_STATION&amp;variables=ATemp,RH&amp;start_date=2020-01-01&amp;end_date=2020-01-31&amp;units=metric&amp;output_format=json\" \\\n     -H \"api-key: ${API_KEY}\"\n</code></pre>"},{"location":"endpoints/timeseries-endpoints/#parameters_2","title":"Parameters","text":"Parameter Type Description Default STA_NAMES string One or more station names (comma-separated) LAKE MEAD_STATION, BLW_STATION variables string One or more variables (comma-separated) ATemp, ATemp_Min, ATemp_Max, BP, BR, Ce, DO, DO_percent, EnergyT, ETo, ETr, evap_1, evap_2, evap_3, evap_4, evap_5, HSEnergyFlux, IncomingSR, inflow, SurfaceT, MO_StabilityL, NC_EnergyStored, NR, NW_AdvectedE, outflow, PH, RH, SamplingD, SkinTemp, SpecConduct, SWin, VP, VPD, WTemp, WVD, WD, WS, PofDays units string Units for returned data (english or metric) metric start_date string Start date (yyyy-mm-dd) 2020-01-01 end_date string End date (yyyy-mm-dd) 2020-01-31 also_return string Additional metadata attributes to include in response output_format string Response format (json or csv) json"},{"location":"endpoints/timeseries-endpoints/#response_2","title":"Response","text":"<p>Returns a list of dictionaries containing timeseries data for the specified stations, variables, and date range.</p>"},{"location":"endpoints/timeseries-endpoints/#notes_1","title":"Notes","text":"<ul> <li>Use the <code>/info/list_STA_NAMES</code> endpoint to discover available station names.</li> <li>Use the <code>/info/list_stations_variables</code> endpoint to discover available variables for stations.</li> <li>Use the <code>/info/list_stations_dates</code> endpoint to discover the valid date range for stations.</li> </ul>"},{"location":"endpoints/timeseries-endpoints/#station-timeseries-data-single-date","title":"Station Timeseries Data (Single Date)","text":"<p>Retrieves timeseries data for all stations on a single date.</p> PythonRcURL <pre><code>import requests\n\nurl = \"https://operevap.dri.edu/timeseries/stations/date\"\nheaders = {\n    \"api-key\": \"YOUR_API_KEY\"\n}\nparams = {\n    \"variables\": \"ATemp,RH\",\n    \"date\": \"2020-01-01\",\n    \"units\": \"metric\",\n    \"output_format\": \"json\"\n}\n\nresponse = requests.get(url, headers=headers, params=params)\ndata = response.json()\nprint(data)\n</code></pre> <pre><code>library(httr)\nlibrary(jsonlite)\n\n# API configuration\napi_key &lt;- \"YOUR_API_KEY\"\nbase_url &lt;- \"https://operevap.dri.edu\"\n\n# Get station data for a single date\nurl &lt;- paste0(base_url, \"/timeseries/stations/date\")\n\nresponse &lt;- GET(\n  url,\n  add_headers(\"api-key\" = api_key),\n  query = list(\n    variables = \"ATemp,RH\",\n    date = \"2020-01-01\",\n    units = \"metric\",\n    output_format = \"json\"\n  )\n)\n\n# Parse response\ndata &lt;- fromJSON(content(response, \"text\", encoding = \"UTF-8\"))\nprint(data)\n</code></pre> <pre><code># Set your API key\nAPI_KEY=\"YOUR_API_KEY\"\n\n# Get station data for a single date\ncurl -X GET \"https://operevap.dri.edu/timeseries/stations/date?variables=ATemp,RH&amp;date=2020-01-01&amp;units=metric&amp;output_format=json\" \\\n     -H \"api-key: ${API_KEY}\"\n</code></pre>"},{"location":"endpoints/timeseries-endpoints/#parameters_3","title":"Parameters","text":"Parameter Type Description Default variables string One or more variables (comma-separated) ATemp, ATemp_Min, ATemp_Max, BP, BR, Ce, DO, DO_percent, EnergyT, ETo, ETr, evap_1, evap_2, evap_3, evap_4, evap_5, HSEnergyFlux, IncomingSR, inflow, SurfaceT, MO_StabilityL, NC_EnergyStored, NR, NW_AdvectedE, outflow, PH, RH, SamplingD, SkinTemp, SpecConduct, SWin, VP, VPD, WTemp, WVD, WD, WS, PofDays units string Units for returned data (english or metric) metric date string Date (yyyy-mm-dd) 2020-01-01 also_return string Additional metadata attributes to include in response output_format string Response format (json or csv) json"},{"location":"endpoints/timeseries-endpoints/#response_3","title":"Response","text":"<p>Returns a list of dictionaries containing timeseries data for all stations for the specified variables and date.</p>"},{"location":"preface/intro/","title":"Reservoir Evaporation API Documentation","text":""},{"location":"preface/intro/#overview","title":"Overview","text":"<p>The Reservoir Evaporation API provides public access to historical and near-real-time daily evaporation estimates from Bureau of Reclamation reservoirs located across 17 western states.</p> <p>This API delivers high-quality data records of evaporation rates and volumes for major reservoirs. The evaporation estimates incorporate meteorological forcing data and reservoir storage information to provide the best available estimates of reservoir evaporation.</p>"},{"location":"preface/intro/#about-this-project","title":"About This Project","text":"<p>Open-water evaporation represents a complex physical process that influences both the water and energy budgets of a lake or reservoir. Though open-water evaporation is critical for water quality, water distribution, and legal accounting, developing reliable estimates is challenging.</p> <p>Historically, water management agencies such as the Bureau of Reclamation (Reclamation) have relied on evaporation estimates from Class A pans for water budget and accounting purposes. While simple and relatively inexpensive to maintain, Class A pans and the associated evaporation estimates have known biases relative to more advanced estimation techniques. This bias, which can depend on water body characteristics like depth and volume, is often attributed to a lack of heat storage in Class A pans relative to real water bodies.</p> <p>This project developed a daily reservoir evaporation database which can be freely accessed and visualized by water managers and stakeholders. This database contains historical and near real-time, high quality data records of evaporation rates and volumes for major reservoirs.</p>"},{"location":"preface/intro/#collaborative-development","title":"Collaborative Development","text":"<p>This API was collaboratively developed by the Bureau of Reclamation (BOR) and Desert Research Institute.</p>"},{"location":"preface/intro/#disclaimer","title":"Disclaimer","text":"<p>Data and information provided through this application are part of an active research project and should be considered provisional and subject to change. Users should perform thorough review prior to operational application and decision making.</p>"},{"location":"preface/intro/#additional-resources","title":"Additional Resources","text":"<ul> <li>Abatzoglou, J. T. (2013), Development of gridded surface meteorological data for ecological applications and modelling. Int. J. Climatol., 33: 121\u2013131.</li> <li>De Pondeca, M. S. F. V., and Coauthors, 2011: The Real-Time Mesoscale Analysis at NOAA's National Centers for Environmental Prediction: Current status and development. Wea. Forecasting, 26, 593\u2013612, https://doi.org/10.1175/WAF-D-10-05037.1.</li> <li>Tanny, J., and Coauthors, 2008: Evaporation from a small water reservoir: Direct measurements and estimates. J. Hydrology, 351, 218-229.</li> <li>Zhao, G., and H. Gao, 2019: Estimating reservoir evaporation losses for the united states: Fusing remote sensing and modeling approaches. Remote Sensing of Environment, 226, 109\u2013124.</li> <li>Zhao, B., and Coauthors, 2023: Developing a Daily Lake Evaporation Model and Generating a Long-term Daily Reservoir Evaporation Dataset in Texas. Submitted to Water Resources Research.</li> </ul>"},{"location":"started/api-playground/","title":"Reservoir Evaporation API Playground","text":""},{"location":"started/authentication/","title":"Authentication","text":""},{"location":"started/authentication/#api-key","title":"API Key","text":"<p>Access to the Reservoir Evaporation API requires an API key. This key must be included with each request to authenticate your application.</p>"},{"location":"started/authentication/#requesting-an-api-key","title":"Requesting an API Key","text":"<p>To obtain an API key, you need to make a request to the authentication endpoint:</p> PythonRcURL <pre><code>import requests\n\nurl = \"https://operevap.dri.edu/auth/request_key\"\nparams = {\n    \"name\": \"John Doe\",\n    \"email\": \"john.doe@example.com\",\n    \"justification\": \"Research on reservoir evaporation for climate impact study\"\n}\n\nresponse = requests.get(url, params=params)\nprint(response.text)\n</code></pre> <pre><code>library(httr)\n\n# API configuration\nbase_url &lt;- \"https://operevap.dri.edu\"\n\n# Request an API key\nurl &lt;- paste0(base_url, \"/auth/request_key\")\n\nresponse &lt;- GET(\n  url,\n  query = list(\n    name = \"John Doe\",\n    email = \"john.doe@example.com\",\n    justification = \"Research on reservoir evaporation for climate impact study\"\n  )\n)\n\n# Print response\ncontent &lt;- content(response, \"text\", encoding = \"UTF-8\")\ncat(content)\n</code></pre> <pre><code># Request an API key\ncurl -X GET \"https://operevap.dri.edu/auth/request_key?name=John%20Doe&amp;email=john.doe@example.com&amp;justification=Research%20on%20reservoir%20evaporation%20for%20climate%20impact%20study\"\n</code></pre>"},{"location":"started/authentication/#parameters","title":"Parameters","text":"Parameter Type Description name string Your full name (First Last) email string A valid email address where the API key will be sent justification string A brief explanation of why you would like an API key and how you will use it"},{"location":"started/authentication/#response","title":"Response","text":"<p>After submitting your request, you should receive an email with your API key within 1 to 2 business days.</p>"},{"location":"started/authentication/#using-your-api-key","title":"Using Your API Key","text":"<p>Once you have received your API key, you must include it in the header of each API request:</p> PythonRcURL <pre><code>import requests\nimport os\n\n# You can store your API key as an environment variable for security\napi_key = os.environ.get(\"OPEREVAP_API_KEY\", \"YOUR_API_KEY\")\n\nurl = \"https://operevap.dri.edu/info/list_datasets\"\nheaders = {\n    \"api-key\": api_key\n}\n\nresponse = requests.get(url, headers=headers)\ndata = response.json()\nprint(data)\n</code></pre> <pre><code>library(httr)\nlibrary(jsonlite)\n\n# API configuration\n# Store your API key in .Renviron for security\napi_key &lt;- Sys.getenv(\"OPEREVAP_API_KEY\", \"YOUR_API_KEY\")\nbase_url &lt;- \"https://operevap.dri.edu\"\n\n# Make a request using your API key\nurl &lt;- paste0(base_url, \"/info/list_datasets\")\n\nresponse &lt;- GET(\n  url,\n  add_headers(\"api-key\" = api_key)\n)\n\n# Parse response\ndata &lt;- fromJSON(content(response, \"text\", encoding = \"UTF-8\"))\nprint(data)\n</code></pre> <pre><code># Set your API key\nAPI_KEY=\"YOUR_API_KEY\"\n\n# Make a request using your API key\ncurl -X GET \"https://operevap.dri.edu/info/list_datasets\" \\\n     -H \"api-key: ${API_KEY}\"\n</code></pre>"},{"location":"started/authentication/#example-getting-csv-output","title":"Example: Getting CSV Output","text":"PythonRcURL <pre><code>import requests\nimport os\n\n# Get API key from environment variable\napi_key = os.environ.get(\"OPEREVAP_API_KEY\", \"YOUR_API_KEY\")\n\nurl = \"https://operevap.dri.edu/info/list_datasets\"\nheaders = {\n    \"api-key\": api_key\n}\nparams = {\n    \"output_format\": \"csv\"\n}\n\nresponse = requests.get(url, headers=headers, params=params)\ncsv_data = response.text\nprint(csv_data)\n\n# Optionally save to file\nwith open('datasets.csv', 'w') as f:\n    f.write(csv_data)\n</code></pre> <pre><code>library(httr)\n\n# API configuration\napi_key &lt;- Sys.getenv(\"OPEREVAP_API_KEY\", \"YOUR_API_KEY\")\nbase_url &lt;- \"https://operevap.dri.edu\"\n\n# Get data in CSV format\nurl &lt;- paste0(base_url, \"/info/list_datasets\")\n\nresponse &lt;- GET(\n  url,\n  add_headers(\"api-key\" = api_key),\n  query = list(output_format = \"csv\")\n)\n\n# Get CSV content\ncsv_data &lt;- content(response, \"text\", encoding = \"UTF-8\")\ncat(csv_data)\n\n# Optionally save to file\nwrite(csv_data, file = \"datasets.csv\")\n\n# Or read directly into a data frame\ncsv_connection &lt;- textConnection(csv_data)\ndatasets_df &lt;- read.csv(csv_connection)\nclose(csv_connection)\nprint(datasets_df)\n</code></pre> <pre><code># Set your API key\nAPI_KEY=\"YOUR_API_KEY\"\n\n# Get data in CSV format\ncurl -X GET \"https://operevap.dri.edu/info/list_datasets?output_format=csv\" \\\n     -H \"api-key: ${API_KEY}\" \\\n     -o datasets.csv\n</code></pre>"},{"location":"started/authentication/#api-key-security","title":"API Key Security","text":"<ul> <li>Keep your API key secure and do not share it publicly.</li> <li>If you believe your API key has been compromised, request a new one.</li> <li>Do not embed your API key directly in client-side code that is accessible to users.</li> <li>Use environment variables or secure configuration files to store your API key:</li> <li>Python: Use <code>os.environ.get(\"OPEREVAP_API_KEY\")</code></li> <li>R: Use <code>Sys.getenv(\"OPEREVAP_API_KEY\")</code></li> <li>Bash/cURL: Use <code>export OPEREVAP_API_KEY=\"your-key\"</code> and reference with <code>${OPEREVAP_API_KEY}</code></li> </ul>"},{"location":"started/getting-started/","title":"Getting Started","text":"<p>This section provides an overview of how to begin using the Reservoir Evaporation API.</p>"},{"location":"started/getting-started/#prerequisites","title":"Prerequisites","text":"<p>Before using the API, you will need:</p> <ol> <li>An API key (see Authentication)</li> <li>Basic understanding of REST APIs and HTTP requests</li> <li>A tool to make HTTP requests (e.g., cURL, Postman, or programming languages like Python, JavaScript, etc.)</li> </ol>"},{"location":"started/getting-started/#base-url","title":"Base URL","text":"<p>All API requests should be made to the base URL of the API:</p> <pre><code>https://operevap.dri.edu\n</code></pre>"},{"location":"started/getting-started/#request-format","title":"Request Format","text":"<p>The API accepts request parameters as query parameters in the URL. Here's an example using Python requests:</p> <pre><code>import requests\n\nparams = {\n    \"RES_NAMES\": \"LAKE ALICE\",\n    \"start_date\": \"2020-01-01\",\n    \"end_date\": \"2020-01-31\"\n}\n\nurl = \"https://operevap.dri.edu/timeseries/daily/reservoirs/daterange\"\nheaders = {\n    \"api-key\": \"YOUR_API_KEY\"\n}\n\nresponse = requests.get(url, params=params, headers=headers)\ndata = response.json()\nprint(data)\n</code></pre>"},{"location":"started/getting-started/#response-format","title":"Response Format","text":"<p>The API returns data in either JSON or CSV format, which can be specified using the <code>output_format</code> parameter in your requests:</p> <ul> <li><code>output_format=json</code> (default)</li> <li><code>output_format=csv</code></li> </ul> <p>Example of requesting CSV output:</p> <pre><code>import requests\n\nparams = {\n    \"RES_NAMES\": \"LAKE ALICE\",\n    \"start_date\": \"2020-01-01\",\n    \"end_date\": \"2020-01-31\",\n    \"output_format\": \"csv\"\n}\n\nurl = \"https://operevap.dri.edu/timeseries/daily/reservoirs/daterange\"\nheaders = {\n    \"api-key\": \"YOUR_API_KEY\"\n}\n\nresponse = requests.get(url, params=params, headers=headers)\ncsv_data = response.text\nprint(csv_data)\n\n# Optionally save to file\nwith open('lake_alice_data.csv', 'w') as f:\n    f.write(csv_data)\n</code></pre>"},{"location":"started/getting-started/#units","title":"Units","text":"<p>For endpoints that return numerical values, you can specify whether you want the data in metric or English units using the <code>units</code> parameter:</p> <ul> <li><code>units=metric</code> (default)</li> <li><code>units=english</code></li> </ul> <p>Example using English units:</p> <pre><code>import requests\n\nparams = {\n    \"RES_NAMES\": \"LAKE ALICE\",\n    \"start_date\": \"2020-01-01\",\n    \"end_date\": \"2020-01-31\",\n    \"units\": \"english\"\n}\n\nurl = \"https://operevap.dri.edu/timeseries/daily/reservoirs/daterange\"\nheaders = {\n    \"api-key\": \"YOUR_API_KEY\"\n}\n\nresponse = requests.get(url, params=params, headers=headers)\ndata = response.json()\nprint(data)\n</code></pre>"},{"location":"started/getting-started/#api-sections","title":"API Sections","text":"<p>The API is organized into the following sections:</p> <ol> <li>Auth - Endpoints for requesting API keys</li> <li>Help/Info - Endpoints for discovering available datasets, variables, reservoirs, stations, and date ranges</li> <li>Metadata - Endpoints for retrieving metadata about reservoirs and stations</li> <li>Timeseries - Endpoints for retrieving timeseries data for reservoirs and stations</li> </ol>"},{"location":"started/getting-started/#python-example","title":"Python Example","text":"<p>A Python example for interacting with the API is available at: https://drive.google.com/drive/folders/1_JAM9JGwf40Tjo3fkx28mIP1tW5M55AO?usp=sharing</p> <p>This example can help you get started with using the API in your Python applications.</p>"},{"location":"started/getting-started/#next-steps","title":"Next Steps","text":"<ol> <li>Request an API key</li> <li>Explore the available reservoirs and stations</li> <li>Retrieve metadata for your reservoirs of interest</li> <li>Retrieve timeseries data for your analysis</li> </ol>"}]}